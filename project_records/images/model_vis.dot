digraph {
	graph [size="455.4,455.4"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	139936689392000 [label="
 (1, 16, 3)" fillcolor=darkolivegreen1]
	139936677060224 [label="ViewBackward
-------------------
self_sizes: (1, 48)"]
	139936677057296 -> 139936677060224
	139936677057296 -> 139936715006528 [dir=none]
	139936715006528 [label="mat1
 (1, 128)" fillcolor=orange]
	139936677057296 -> 139937993796096 [dir=none]
	139937993796096 [label="mat2
 (128, 48)" fillcolor=orange]
	139936677057296 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :       (1, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :      (128, 48)
mat2_strides:       (1, 128)"]
	139936677057104 -> 139936677057296
	139936661291648 [label="model._mlp.4.bias
 (48)" fillcolor=lightblue]
	139936661291648 -> 139936677057104
	139936677057104 [label=AccumulateGrad]
	139936677057344 -> 139936677057296
	139936677057344 -> 139936685875008 [dir=none]
	139936685875008 [label="self
 (1, 128)" fillcolor=orange]
	139936677057344 [label="ReluBackward0
--------------------
self: [saved tensor]"]
	139938008416368 -> 139936677057344
	139938008416368 -> 139936687240896 [dir=none]
	139936687240896 [label="mat1
 (1, 128)" fillcolor=orange]
	139938008416368 -> 139936692358656 [dir=none]
	139936692358656 [label="mat2
 (128, 128)" fillcolor=orange]
	139938008416368 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :       (1, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139938008418192 -> 139938008416368
	139936661291328 [label="model._mlp.2.bias
 (128)" fillcolor=lightblue]
	139936661291328 -> 139938008418192
	139938008418192 [label=AccumulateGrad]
	139938008418672 -> 139938008416368
	139938008418672 -> 139936690406336 [dir=none]
	139936690406336 [label="self
 (1, 128)" fillcolor=orange]
	139938008418672 [label="ReluBackward0
--------------------
self: [saved tensor]"]
	139938008419056 -> 139938008418672
	139938008419056 -> 139936717235584 [dir=none]
	139936717235584 [label="mat1
 (1, 128)" fillcolor=orange]
	139938008419056 -> 139936690405760 [dir=none]
	139936690405760 [label="mat2
 (128, 128)" fillcolor=orange]
	139938008419056 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :       (1, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139936676926944 -> 139938008419056
	139936661291072 [label="model._mlp.0.bias
 (128)" fillcolor=lightblue]
	139936661291072 -> 139936676926944
	139936676926944 [label=AccumulateGrad]
	139936676927616 -> 139938008419056
	139936676927616 [label="ViewBackward
------------------
self_sizes: (128,)"]
	139938006267408 -> 139936676927616
	139938006267408 [label="CatBackward
-----------
dim: 0"]
	139936687232000 -> 139938006267408
	139936687232000 [label="SelectBackward
---------------------
dim       :         0
index     :         0
self_sizes: (68, 128)"]
	139936687232576 -> 139936687232000
	139936687232576 -> 139936690407040 [dir=none]
	139936690407040 [label="result
 (68, 128)" fillcolor=orange]
	139936687232576 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936687233392 -> 139936687232576
	139936687233392 [label="AddBackward0
------------
alpha: 1"]
	139936687233824 -> 139936687233392
	139936687233824 -> 139936685056512 [dir=none]
	139936685056512 [label="mat1
 (68, 128)" fillcolor=orange]
	139936687233824 -> 139936685900032 [dir=none]
	139936685900032 [label="mat2
 (128, 128)" fillcolor=orange]
	139936687233824 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (68, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139936687231808 -> 139936687233824
	139936658267456 [label="model.actor2actor_attention.attention_layers.3.output_linear.bias
 (128)" fillcolor=lightblue]
	139936658267456 -> 139936687231808
	139936687231808 [label=AccumulateGrad]
	139936687234352 -> 139936687233824
	139936687234352 -> 139936717234240 [dir=none]
	139936717234240 [label="result
 (68, 128)" fillcolor=orange]
	139936687234352 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936687234688 -> 139936687234352
	139936687234688 -> 139936685809024 [dir=none]
	139936685809024 [label="bias
 (128)" fillcolor=orange]
	139936687234688 -> 139936685808704 [dir=none]
	139936685808704 [label="input
 (68, 128)" fillcolor=orange]
	139936687234688 -> 139936685809536 [dir=none]
	139936685809536 [label="result1
 (68, 1)" fillcolor=orange]
	139936687234688 -> 139936685806080 [dir=none]
	139936685806080 [label="result2
 (68, 1)" fillcolor=orange]
	139936687234688 -> 139936692358400 [dir=none]
	139936692358400 [label="weight
 (128)" fillcolor=orange]
	139936687234688 [label="NativeLayerNormBackward
--------------------------------
bias            : [saved tensor]
eps             :          1e-05
input           : [saved tensor]
normalized_shape:         (128,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	139936676746624 -> 139936687234688
	139936676746624 -> 139936685902080 [dir=none]
	139936685902080 [label="index
 (590)" fillcolor=orange]
	139936676746624 -> 139936679729088 [dir=none]
	139936679729088 [label="source
 (590, 128)" fillcolor=orange]
	139936676746624 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139936676745280 -> 139936676746624
	139936676745280 [label=CloneBackward]
	139936676748496 -> 139936676745280
	139936676748496 -> 139936685902400 [dir=none]
	139936685902400 [label="result
 (68, 128)" fillcolor=orange]
	139936676748496 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936676748208 -> 139936676748496
	139936676748208 -> 139936685900096 [dir=none]
	139936685900096 [label="mat1
 (68, 128)" fillcolor=orange]
	139936676748208 -> 139936679729856 [dir=none]
	139936679729856 [label="mat2
 (128, 128)" fillcolor=orange]
	139936676748208 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (68, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139936676746960 -> 139936676748208
	139936658265280 [label="model.actor2actor_attention.attention_layers.3.dst_encoder.0.bias
 (128)" fillcolor=lightblue]
	139936658265280 -> 139936676746960
	139936676746960 [label=AccumulateGrad]
	139936687234064 -> 139936676748208
	139936687234064 -> 139936693243200 [dir=none]
	139936693243200 [label="result
 (68, 128)" fillcolor=orange]
	139936687234064 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936676858368 -> 139936687234064
	139936676858368 [label="AddBackward0
------------
alpha: 1"]
	139936669975264 -> 139936676858368
	139936669975264 -> 139936693240192 [dir=none]
	139936693240192 [label="mat1
 (68, 128)" fillcolor=orange]
	139936669975264 -> 139936693242752 [dir=none]
	139936693242752 [label="mat2
 (128, 128)" fillcolor=orange]
	139936669975264 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (68, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139936669976560 -> 139936669975264
	139936658264256 [label="model.actor2actor_attention.attention_layers.2.output_linear.bias
 (128)" fillcolor=lightblue]
	139936658264256 -> 139936669976560
	139936669976560 [label=AccumulateGrad]
	139936669975840 -> 139936669975264
	139936669975840 -> 139936679729984 [dir=none]
	139936679729984 [label="result
 (68, 128)" fillcolor=orange]
	139936669975840 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936669977040 -> 139936669975840
	139936669977040 -> 139936679729664 [dir=none]
	139936679729664 [label="bias
 (128)" fillcolor=orange]
	139936669977040 -> 139936689860544 [dir=none]
	139936689860544 [label="input
 (68, 128)" fillcolor=orange]
	139936669977040 -> 139936689857344 [dir=none]
	139936689857344 [label="result1
 (68, 1)" fillcolor=orange]
	139936669977040 -> 139936689859776 [dir=none]
	139936689859776 [label="result2
 (68, 1)" fillcolor=orange]
	139936669977040 -> 139936689859968 [dir=none]
	139936689859968 [label="weight
 (128)" fillcolor=orange]
	139936669977040 [label="NativeLayerNormBackward
--------------------------------
bias            : [saved tensor]
eps             :          1e-05
input           : [saved tensor]
normalized_shape:         (128,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	139936669978096 -> 139936669977040
	139936669978096 -> 139936693242496 [dir=none]
	139936693242496 [label="index
 (590)" fillcolor=orange]
	139936669978096 -> 139936693243392 [dir=none]
	139936693243392 [label="source
 (590, 128)" fillcolor=orange]
	139936669978096 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139936669977088 -> 139936669978096
	139936669977088 [label=CloneBackward]
	139936669978432 -> 139936669977088
	139936669978432 -> 139936693241600 [dir=none]
	139936693241600 [label="result
 (68, 128)" fillcolor=orange]
	139936669978432 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936669974736 -> 139936669978432
	139936669974736 -> 139936689858624 [dir=none]
	139936689858624 [label="mat1
 (68, 128)" fillcolor=orange]
	139936669974736 -> 139936689858240 [dir=none]
	139936689858240 [label="mat2
 (128, 128)" fillcolor=orange]
	139936669974736 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (68, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139936676751344 -> 139936669974736
	139936657401856 [label="model.actor2actor_attention.attention_layers.2.dst_encoder.0.bias
 (128)" fillcolor=lightblue]
	139936657401856 -> 139936676751344
	139936676751344 [label=AccumulateGrad]
	139936669975600 -> 139936669974736
	139936669975600 -> 139936689857600 [dir=none]
	139936689857600 [label="result
 (68, 128)" fillcolor=orange]
	139936669975600 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139938013209120 -> 139936669975600
	139938013209120 [label="AddBackward0
------------
alpha: 1"]
	139938013209936 -> 139938013209120
	139938013209936 -> 139936689860480 [dir=none]
	139936689860480 [label="mat1
 (68, 128)" fillcolor=orange]
	139938013209936 -> 139936689858432 [dir=none]
	139936689858432 [label="mat2
 (128, 128)" fillcolor=orange]
	139938013209936 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (68, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139938013210128 -> 139938013209936
	139936657400832 [label="model.actor2actor_attention.attention_layers.1.output_linear.bias
 (128)" fillcolor=lightblue]
	139936657400832 -> 139938013210128
	139938013210128 [label=AccumulateGrad]
	139938013210320 -> 139938013209936
	139938013210320 -> 139938268326528 [dir=none]
	139938268326528 [label="result
 (68, 128)" fillcolor=orange]
	139938013210320 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139938013210512 -> 139938013210320
	139938013210512 -> 139938268326400 [dir=none]
	139938268326400 [label="bias
 (128)" fillcolor=orange]
	139938013210512 -> 139938268326720 [dir=none]
	139938268326720 [label="input
 (68, 128)" fillcolor=orange]
	139938013210512 -> 139938268324224 [dir=none]
	139938268324224 [label="result1
 (68, 1)" fillcolor=orange]
	139938013210512 -> 139938268326848 [dir=none]
	139938268326848 [label="result2
 (68, 1)" fillcolor=orange]
	139938013210512 -> 139938268324672 [dir=none]
	139938268324672 [label="weight
 (128)" fillcolor=orange]
	139938013210512 [label="NativeLayerNormBackward
--------------------------------
bias            : [saved tensor]
eps             :          1e-05
input           : [saved tensor]
normalized_shape:         (128,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	139938013211472 -> 139938013210512
	139938013211472 -> 139938268326080 [dir=none]
	139938268326080 [label="index
 (590)" fillcolor=orange]
	139938013211472 -> 139938268327104 [dir=none]
	139938268327104 [label="source
 (590, 128)" fillcolor=orange]
	139938013211472 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139938013209408 -> 139938013211472
	139938013209408 [label=CloneBackward]
	139938013212432 -> 139938013209408
	139938013212432 -> 139938268326656 [dir=none]
	139938268326656 [label="result
 (68, 128)" fillcolor=orange]
	139938013212432 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936677456096 -> 139938013212432
	139936677456096 -> 139938268325504 [dir=none]
	139938268325504 [label="mat1
 (68, 128)" fillcolor=orange]
	139936677456096 -> 139938268324800 [dir=none]
	139938268324800 [label="mat2
 (128, 128)" fillcolor=orange]
	139936677456096 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (68, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139936677455856 -> 139936677456096
	139936657562432 [label="model.actor2actor_attention.attention_layers.1.dst_encoder.0.bias
 (128)" fillcolor=lightblue]
	139936657562432 -> 139936677455856
	139936677455856 [label=AccumulateGrad]
	139938013209312 -> 139936677456096
	139938013209312 -> 139936714791680 [dir=none]
	139936714791680 [label="result
 (68, 128)" fillcolor=orange]
	139938013209312 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936677454944 -> 139938013209312
	139936677454944 [label="AddBackward0
------------
alpha: 1"]
	139936677456864 -> 139936677454944
	139936677456864 -> 139936683107520 [dir=none]
	139936683107520 [label="mat1
 (68, 128)" fillcolor=orange]
	139936677456864 -> 139936683109568 [dir=none]
	139936683109568 [label="mat2
 (128, 128)" fillcolor=orange]
	139936677456864 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (68, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139936677457056 -> 139936677456864
	139936657561408 [label="model.actor2actor_attention.attention_layers.0.output_linear.bias
 (128)" fillcolor=lightblue]
	139936657561408 -> 139936677457056
	139936677457056 [label=AccumulateGrad]
	139936677457248 -> 139936677456864
	139936677457248 -> 139936656951296 [dir=none]
	139936656951296 [label="result
 (68, 128)" fillcolor=orange]
	139936677457248 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936677457392 -> 139936677457248
	139936677457392 -> 139938268324864 [dir=none]
	139938268324864 [label="bias
 (128)" fillcolor=orange]
	139936677457392 -> 139938268327680 [dir=none]
	139938268327680 [label="input
 (68, 128)" fillcolor=orange]
	139936677457392 -> 139938268327360 [dir=none]
	139938268327360 [label="result1
 (68, 1)" fillcolor=orange]
	139936677457392 -> 139938268326464 [dir=none]
	139938268326464 [label="result2
 (68, 1)" fillcolor=orange]
	139936677457392 -> 139938268324352 [dir=none]
	139938268324352 [label="weight
 (128)" fillcolor=orange]
	139936677457392 [label="NativeLayerNormBackward
--------------------------------
bias            : [saved tensor]
eps             :          1e-05
input           : [saved tensor]
normalized_shape:         (128,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	139936677454464 -> 139936677457392
	139936677454464 -> 139936683109184 [dir=none]
	139936683109184 [label="index
 (590)" fillcolor=orange]
	139936677454464 -> 139936683109696 [dir=none]
	139936683109696 [label="source
 (590, 128)" fillcolor=orange]
	139936677454464 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139936677455184 -> 139936677454464
	139936677455184 [label=CloneBackward]
	139936677454848 -> 139936677455184
	139936677454848 -> 139936683107840 [dir=none]
	139936683107840 [label="result
 (68, 128)" fillcolor=orange]
	139936677454848 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936677457152 -> 139936677454848
	139936677457152 -> 139936683106816 [dir=none]
	139936683106816 [label="mat1
 (68, 128)" fillcolor=orange]
	139936677457152 -> 139936683108416 [dir=none]
	139936683108416 [label="mat2
 (128, 128)" fillcolor=orange]
	139936677457152 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (68, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139936677106064 -> 139936677457152
	139936675262080 [label="model.actor2actor_attention.attention_layers.0.dst_encoder.0.bias
 (128)" fillcolor=lightblue]
	139936675262080 -> 139936677106064
	139936677106064 [label=AccumulateGrad]
	139936677456192 -> 139936677457152
	139936677456192 -> 139936683110016 [dir=none]
	139936683110016 [label="result
 (68, 128)" fillcolor=orange]
	139936677456192 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936677105872 -> 139936677456192
	139936677105872 [label="AddBackward0
------------
alpha: 1"]
	139936677106400 -> 139936677105872
	139936677106400 -> 139936661196288 [dir=none]
	139936661196288 [label="mat1
 (68, 128)" fillcolor=orange]
	139936677106400 -> 139936661196224 [dir=none]
	139936661196224 [label="mat2
 (128, 128)" fillcolor=orange]
	139936677106400 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (68, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139936677107216 -> 139936677106400
	139936675260544 [label="model.lane2actor_attention.attention_layers.3.output_linear.bias
 (128)" fillcolor=lightblue]
	139936675260544 -> 139936677107216
	139936677107216 [label=AccumulateGrad]
	139936677106832 -> 139936677106400
	139936677106832 -> 139936676822720 [dir=none]
	139936676822720 [label="result
 (68, 128)" fillcolor=orange]
	139936677106832 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936677107600 -> 139936677106832
	139936677107600 -> 139936676822464 [dir=none]
	139936676822464 [label="bias
 (128)" fillcolor=orange]
	139936677107600 -> 139936693247744 [dir=none]
	139936693247744 [label="input
 (68, 128)" fillcolor=orange]
	139936677107600 -> 139936693247168 [dir=none]
	139936693247168 [label="result1
 (68, 1)" fillcolor=orange]
	139936677107600 -> 139936693247552 [dir=none]
	139936693247552 [label="result2
 (68, 1)" fillcolor=orange]
	139936677107600 -> 139936693247616 [dir=none]
	139936693247616 [label="weight
 (128)" fillcolor=orange]
	139936677107600 [label="NativeLayerNormBackward
--------------------------------
bias            : [saved tensor]
eps             :          1e-05
input           : [saved tensor]
normalized_shape:         (128,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	139936677108368 -> 139936677107600
	139936677108368 -> 139936661192768 [dir=none]
	139936661192768 [label="index
 (156865)" fillcolor=orange]
	139936677108368 -> 139936661192960 [dir=none]
	139936661192960 [label="source
 (156865, 128)" fillcolor=orange]
	139936677108368 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139936677108848 -> 139936677108368
	139936677108848 [label=CloneBackward]
	139936677108944 -> 139936677108848
	139936677108944 -> 139936693245184 [dir=none]
	139936693245184 [label="result
 (68, 128)" fillcolor=orange]
	139936677108944 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936677109424 -> 139936677108944
	139936677109424 -> 139936693247232 [dir=none]
	139936693247232 [label="mat1
 (68, 128)" fillcolor=orange]
	139936677109424 -> 139936661194432 [dir=none]
	139936661194432 [label="mat2
 (128, 128)" fillcolor=orange]
	139936677109424 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (68, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139936677105968 -> 139936677109424
	139936675258432 [label="model.lane2actor_attention.attention_layers.3.dst_encoder.0.bias
 (128)" fillcolor=lightblue]
	139936675258432 -> 139936677105968
	139936677105968 [label=AccumulateGrad]
	139936677106640 -> 139936677109424
	139936677106640 -> 139936693244480 [dir=none]
	139936693244480 [label="result
 (68, 128)" fillcolor=orange]
	139936677106640 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936677107360 -> 139936677106640
	139936677107360 [label="AddBackward0
------------
alpha: 1"]
	139936677108272 -> 139936677107360
	139936677108272 -> 139936693246912 [dir=none]
	139936693246912 [label="mat1
 (68, 128)" fillcolor=orange]
	139936677108272 -> 139936661788672 [dir=none]
	139936661788672 [label="mat2
 (128, 128)" fillcolor=orange]
	139936677108272 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (68, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139936677109280 -> 139936677108272
	139936675462080 [label="model.lane2actor_attention.attention_layers.2.output_linear.bias
 (128)" fillcolor=lightblue]
	139936675462080 -> 139936677109280
	139936677109280 [label=AccumulateGrad]
	139936677109376 -> 139936677108272
	139936677109376 -> 139936661196416 [dir=none]
	139936661196416 [label="result
 (68, 128)" fillcolor=orange]
	139936677109376 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936677106112 -> 139936677109376
	139936677106112 -> 139936661196032 [dir=none]
	139936661196032 [label="bias
 (128)" fillcolor=orange]
	139936677106112 -> 139936661193472 [dir=none]
	139936661193472 [label="input
 (68, 128)" fillcolor=orange]
	139936677106112 -> 139936661790272 [dir=none]
	139936661790272 [label="result1
 (68, 1)" fillcolor=orange]
	139936677106112 -> 139936661787264 [dir=none]
	139936661787264 [label="result2
 (68, 1)" fillcolor=orange]
	139936677106112 -> 139936661789504 [dir=none]
	139936661789504 [label="weight
 (128)" fillcolor=orange]
	139936677106112 [label="NativeLayerNormBackward
--------------------------------
bias            : [saved tensor]
eps             :          1e-05
input           : [saved tensor]
normalized_shape:         (128,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	139936693187632 -> 139936677106112
	139936693187632 -> 139936661788224 [dir=none]
	139936661788224 [label="index
 (156865)" fillcolor=orange]
	139936693187632 -> 139936661790528 [dir=none]
	139936661790528 [label="source
 (156865, 128)" fillcolor=orange]
	139936693187632 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139936693188208 -> 139936693187632
	139936693188208 [label=CloneBackward]
	139936693188352 -> 139936693188208
	139936693188352 -> 139936661790592 [dir=none]
	139936661790592 [label="result
 (68, 128)" fillcolor=orange]
	139936693188352 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936693188544 -> 139936693188352
	139936693188544 -> 139936661790464 [dir=none]
	139936661790464 [label="mat1
 (68, 128)" fillcolor=orange]
	139936693188544 -> 139936661787328 [dir=none]
	139936661787328 [label="mat2
 (128, 128)" fillcolor=orange]
	139936693188544 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (68, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139936693188832 -> 139936693188544
	139936675459904 [label="model.lane2actor_attention.attention_layers.2.dst_encoder.0.bias
 (128)" fillcolor=lightblue]
	139936675459904 -> 139936693188832
	139936693188832 [label=AccumulateGrad]
	139936677107696 -> 139936693188544
	139936677107696 -> 139936677458048 [dir=none]
	139936677458048 [label="result
 (68, 128)" fillcolor=orange]
	139936677107696 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936693189456 -> 139936677107696
	139936693189456 [label="AddBackward0
------------
alpha: 1"]
	139936693190080 -> 139936693189456
	139936693190080 -> 139936677171008 [dir=none]
	139936677171008 [label="mat1
 (68, 128)" fillcolor=orange]
	139936693190080 -> 139936677169792 [dir=none]
	139936677169792 [label="mat2
 (128, 128)" fillcolor=orange]
	139936693190080 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (68, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139936693190176 -> 139936693190080
	139936675090176 [label="model.lane2actor_attention.attention_layers.1.output_linear.bias
 (128)" fillcolor=lightblue]
	139936675090176 -> 139936693190176
	139936693190176 [label=AccumulateGrad]
	139936693190368 -> 139936693190080
	139936693190368 -> 139936661789824 [dir=none]
	139936661789824 [label="result
 (68, 128)" fillcolor=orange]
	139936693190368 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936693190464 -> 139936693190368
	139936693190464 -> 139936661790400 [dir=none]
	139936661790400 [label="bias
 (128)" fillcolor=orange]
	139936693190464 -> 139936677169344 [dir=none]
	139936677169344 [label="input
 (68, 128)" fillcolor=orange]
	139936693190464 -> 139936677169472 [dir=none]
	139936677169472 [label="result1
 (68, 1)" fillcolor=orange]
	139936693190464 -> 139936677168832 [dir=none]
	139936677168832 [label="result2
 (68, 1)" fillcolor=orange]
	139936693190464 -> 139936677169920 [dir=none]
	139936677169920 [label="weight
 (128)" fillcolor=orange]
	139936693190464 [label="NativeLayerNormBackward
--------------------------------
bias            : [saved tensor]
eps             :          1e-05
input           : [saved tensor]
normalized_shape:         (128,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	139936693188928 -> 139936693190464
	139936693188928 -> 139936677167232 [dir=none]
	139936677167232 [label="index
 (156865)" fillcolor=orange]
	139936693188928 -> 139936677169216 [dir=none]
	139936677169216 [label="source
 (156865, 128)" fillcolor=orange]
	139936693188928 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139936693187344 -> 139936693188928
	139936693187344 [label=CloneBackward]
	139936693189600 -> 139936693187344
	139936693189600 -> 139936689406272 [dir=none]
	139936689406272 [label="result
 (68, 128)" fillcolor=orange]
	139936693189600 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936693190320 -> 139936693189600
	139936693190320 -> 139936689407296 [dir=none]
	139936689407296 [label="mat1
 (68, 128)" fillcolor=orange]
	139936693190320 -> 139936689406592 [dir=none]
	139936689406592 [label="mat2
 (128, 128)" fillcolor=orange]
	139936693190320 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (68, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139936693189888 -> 139936693190320
	139936675088000 [label="model.lane2actor_attention.attention_layers.1.dst_encoder.0.bias
 (128)" fillcolor=lightblue]
	139936675088000 -> 139936693189888
	139936693189888 [label=AccumulateGrad]
	139936693189696 -> 139936693190320
	139936693189696 -> 139936677168768 [dir=none]
	139936677168768 [label="result
 (68, 128)" fillcolor=orange]
	139936693189696 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936686548160 -> 139936693189696
	139936686548160 [label="AddBackward0
------------
alpha: 1"]
	139936686547968 -> 139936686548160
	139936686547968 -> 139936677168512 [dir=none]
	139936677168512 [label="mat1
 (68, 128)" fillcolor=orange]
	139936686547968 -> 139936677168896 [dir=none]
	139936677168896 [label="mat2
 (128, 128)" fillcolor=orange]
	139936686547968 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (68, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139936686549312 -> 139936686547968
	139936675086976 [label="model.lane2actor_attention.attention_layers.0.output_linear.bias
 (128)" fillcolor=lightblue]
	139936675086976 -> 139936686549312
	139936686549312 [label=AccumulateGrad]
	139936686547728 -> 139936686547968
	139936686547728 -> 139936689409984 [dir=none]
	139936689409984 [label="result
 (68, 128)" fillcolor=orange]
	139936686547728 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936686550272 -> 139936686547728
	139936686550272 -> 139936689407424 [dir=none]
	139936689407424 [label="bias
 (128)" fillcolor=orange]
	139936686550272 -> 139936689408256 [dir=none]
	139936689408256 [label="input
 (68, 128)" fillcolor=orange]
	139936686550272 -> 139936689409088 [dir=none]
	139936689409088 [label="result1
 (68, 1)" fillcolor=orange]
	139936686550272 -> 139936689408640 [dir=none]
	139936689408640 [label="result2
 (68, 1)" fillcolor=orange]
	139936686550272 -> 139938016745792 [dir=none]
	139938016745792 [label="weight
 (128)" fillcolor=orange]
	139936686550272 [label="NativeLayerNormBackward
--------------------------------
bias            : [saved tensor]
eps             :          1e-05
input           : [saved tensor]
normalized_shape:         (128,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	139936686550368 -> 139936686550272
	139936686550368 -> 139938016744768 [dir=none]
	139938016744768 [label="index
 (156865)" fillcolor=orange]
	139936686550368 -> 139938016745024 [dir=none]
	139938016745024 [label="source
 (156865, 128)" fillcolor=orange]
	139936686550368 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139939050570128 -> 139936686550368
	139939050570128 [label=CloneBackward]
	139939050569840 -> 139939050570128
	139939050569840 -> 139938016743744 [dir=none]
	139938016743744 [label="result
 (68, 128)" fillcolor=orange]
	139939050569840 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139939050570656 -> 139939050569840
	139939050570656 -> 139938016746816 [dir=none]
	139938016746816 [label="mat1
 (68, 128)" fillcolor=orange]
	139939050570656 -> 139938016744320 [dir=none]
	139938016744320 [label="mat2
 (128, 128)" fillcolor=orange]
	139939050570656 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (68, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139939050570512 -> 139939050570656
	139936673413568 [label="model.lane2actor_attention.attention_layers.0.dst_encoder.0.bias
 (128)" fillcolor=lightblue]
	139936673413568 -> 139939050570512
	139939050570512 [label=AccumulateGrad]
	139936686547248 -> 139939050570656
	139936686547248 [label="CatBackward
-----------
dim: 0"]
	139939050571616 -> 139936686547248
	139939050571616 -> 139938016746048 [dir=none]
	139938016746048 [label="input
 (1, 128)" fillcolor=orange]
	139939050571616 -> 139938016743616 [dir=none]
	139938016743616 [label="result1
 (1, 1)" fillcolor=orange]
	139939050571616 -> 139938016747008 [dir=none]
	139938016747008 [label="result2
 (1, 1)" fillcolor=orange]
	139939050571616 -> 139938016744704 [dir=none]
	139938016744704 [label="weight
 (128)" fillcolor=orange]
	139939050571616 [label="NativeGroupNormBackward
-----------------------
C      :            128
HxW    :              1
N      :              1
eps    :          1e-05
group  :              1
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	139939050571760 -> 139939050571616
	139939050571760 -> 139938016746432 [dir=none]
	139938016746432 [label="mat2
 (128, 128)" fillcolor=orange]
	139939050571760 -> 139938016743808 [dir=none]
	139938016743808 [label="self
 (1, 128)" fillcolor=orange]
	139939050571760 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :       (1, 128)
self_strides:       (128, 1)"]
	139939050572000 -> 139939050571760
	139939050572000 -> 139938016744832 [dir=none]
	139938016744832 [label="result
 (1, 128)" fillcolor=orange]
	139939050572000 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139939050572192 -> 139939050572000
	139939050572192 -> 139938016745536 [dir=none]
	139938016745536 [label="mat1
 (1, 128)" fillcolor=orange]
	139939050572192 -> 139938016747136 [dir=none]
	139938016747136 [label="mat2
 (128, 128)" fillcolor=orange]
	139939050572192 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :       (1, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139939050572336 -> 139939050572192
	139936673034944 [label="model.ego_feature_extractor.2.bias
 (128)" fillcolor=lightblue]
	139936673034944 -> 139939050572336
	139939050572336 [label=AccumulateGrad]
	139939050572240 -> 139939050572192
	139939050572240 -> 139938016745088 [dir=none]
	139938016745088 [label="result
 (1, 128)" fillcolor=orange]
	139939050572240 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139939050572432 -> 139939050572240
	139939050572432 -> 139938016745984 [dir=none]
	139938016745984 [label="mat1
 (1, 15)" fillcolor=orange]
	139939050572432 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :        (1, 15)
mat1_strides:             ()
mat2        :           None
mat2_sizes  :      (15, 128)
mat2_strides:        (1, 15)"]
	139939050572720 -> 139939050572432
	139936673034496 [label="model.ego_feature_extractor.0.bias
 (128)" fillcolor=lightblue]
	139936673034496 -> 139939050572720
	139939050572720 [label=AccumulateGrad]
	139939050572624 -> 139939050572432
	139939050572624 [label=TBackward]
	139939050572768 -> 139939050572624
	139936673034688 [label="model.ego_feature_extractor.0.weight
 (128, 15)" fillcolor=lightblue]
	139936673034688 -> 139939050572768
	139939050572768 [label=AccumulateGrad]
	139939050572048 -> 139939050572192
	139939050572048 [label=TBackward]
	139939050572816 -> 139939050572048
	139936673034752 [label="model.ego_feature_extractor.2.weight
 (128, 128)" fillcolor=lightblue]
	139936673034752 -> 139939050572816
	139939050572816 [label=AccumulateGrad]
	139939050571952 -> 139939050571760
	139939050571952 [label=TBackward]
	139939050572576 -> 139939050571952
	139936673035392 [label="model.ego_feature_extractor.4.linear.weight
 (128, 128)" fillcolor=lightblue]
	139936673035392 -> 139939050572576
	139939050572576 [label=AccumulateGrad]
	139939050571664 -> 139939050571616
	139936673035456 [label="model.ego_feature_extractor.4.norm.weight
 (128)" fillcolor=lightblue]
	139936673035456 -> 139939050571664
	139939050571664 [label=AccumulateGrad]
	139939050571184 -> 139939050571616
	139936673035712 [label="model.ego_feature_extractor.4.norm.bias
 (128)" fillcolor=lightblue]
	139936673035712 -> 139939050571184
	139939050571184 [label=AccumulateGrad]
	139939050571568 -> 139936686547248
	139939050571568 -> 139938016747392 [dir=none]
	139938016747392 [label="input
 (67, 128)" fillcolor=orange]
	139939050571568 -> 139938016746368 [dir=none]
	139938016746368 [label="result1
 (67, 1)" fillcolor=orange]
	139939050571568 -> 139938016747328 [dir=none]
	139938016747328 [label="result2
 (67, 1)" fillcolor=orange]
	139939050571568 -> 139938016743680 [dir=none]
	139938016743680 [label="weight
 (128)" fillcolor=orange]
	139939050571568 [label="NativeGroupNormBackward
-----------------------
C      :            128
HxW    :              1
N      :             67
eps    :          1e-05
group  :              1
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	139939050572384 -> 139939050571568
	139939050572384 -> 139938016746624 [dir=none]
	139938016746624 [label="mat2
 (128, 128)" fillcolor=orange]
	139939050572384 -> 139938016744960 [dir=none]
	139938016744960 [label="self
 (67, 128)" fillcolor=orange]
	139939050572384 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :      (67, 128)
self_strides:       (128, 1)"]
	139939050572528 -> 139939050572384
	139939050572528 -> 139938016746560 [dir=none]
	139938016746560 [label="self
 (67, 128)" fillcolor=orange]
	139939050572528 [label="ReluBackward0
--------------------
self: [saved tensor]"]
	139939050573152 -> 139939050572528
	139939050573152 -> 139938016745408 [dir=none]
	139938016745408 [label="mat1
 (67, 128)" fillcolor=orange]
	139939050573152 -> 139938016744896 [dir=none]
	139938016744896 [label="mat2
 (128, 128)" fillcolor=orange]
	139939050573152 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (67, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139939050573296 -> 139939050573152
	139936673036672 [label="model.agent_feature_extractor.2.bias
 (128)" fillcolor=lightblue]
	139936673036672 -> 139939050573296
	139939050573296 [label=AccumulateGrad]
	139939050573200 -> 139939050573152
	139939050573200 -> 139938016743552 [dir=none]
	139938016743552 [label="result
 (67, 128)" fillcolor=orange]
	139939050573200 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139939050573392 -> 139939050573200
	139939050573392 -> 139938016743488 [dir=none]
	139938016743488 [label="mat1
 (67, 40)" fillcolor=orange]
	139939050573392 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :       (67, 40)
mat1_strides:             ()
mat2        :           None
mat2_sizes  :      (40, 128)
mat2_strides:        (1, 40)"]
	139939050573680 -> 139939050573392
	139936673036096 [label="model.agent_feature_extractor.0.bias
 (128)" fillcolor=lightblue]
	139936673036096 -> 139939050573680
	139939050573680 [label=AccumulateGrad]
	139939050573584 -> 139939050573392
	139939050573584 [label=TBackward]
	139939050573728 -> 139939050573584
	139936673036352 [label="model.agent_feature_extractor.0.weight
 (128, 40)" fillcolor=lightblue]
	139936673036352 -> 139939050573728
	139939050573728 [label=AccumulateGrad]
	139939050572912 -> 139939050573152
	139939050572912 [label=TBackward]
	139939050573776 -> 139939050572912
	139936673036480 [label="model.agent_feature_extractor.2.weight
 (128, 128)" fillcolor=lightblue]
	139936673036480 -> 139939050573776
	139939050573776 [label=AccumulateGrad]
	139939050572144 -> 139939050572384
	139939050572144 [label=TBackward]
	139939050573536 -> 139939050572144
	139936673037120 [label="model.agent_feature_extractor.4.linear.weight
 (128, 128)" fillcolor=lightblue]
	139936673037120 -> 139939050573536
	139939050573536 [label=AccumulateGrad]
	139939050571856 -> 139939050571568
	139936673037184 [label="model.agent_feature_extractor.4.norm.weight
 (128)" fillcolor=lightblue]
	139936673037184 -> 139939050571856
	139939050571856 [label=AccumulateGrad]
	139939050571808 -> 139939050571568
	139936673037440 [label="model.agent_feature_extractor.4.norm.bias
 (128)" fillcolor=lightblue]
	139936673037440 -> 139939050571808
	139939050571808 [label=AccumulateGrad]
	139939050570560 -> 139939050570656
	139939050570560 [label=TBackward]
	139939050572960 -> 139939050570560
	139936673413504 [label="model.lane2actor_attention.attention_layers.0.dst_encoder.0.weight
 (128, 128)" fillcolor=lightblue]
	139936673413504 -> 139939050572960
	139939050572960 [label=AccumulateGrad]
	139939050572096 -> 139936686550368
	139939050572096 -> 139938016745920 [dir=none]
	139938016745920 [label="mat1
 (156865, 128)" fillcolor=orange]
	139939050572096 -> 139938016745600 [dir=none]
	139938016745600 [label="mat2
 (128, 128)" fillcolor=orange]
	139939050572096 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :  (156865, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139939050570032 -> 139939050572096
	139936673415040 [label="model.lane2actor_attention.attention_layers.0.edge_encoder.2.bias
 (128)" fillcolor=lightblue]
	139936673415040 -> 139939050570032
	139939050570032 [label=AccumulateGrad]
	139939050570800 -> 139939050572096
	139939050570800 -> 139938016745728 [dir=none]
	139938016745728 [label="result
 (156865, 128)" fillcolor=orange]
	139939050570800 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139939050570176 -> 139939050570800
	139939050570176 -> 139938016744064 [dir=none]
	139938016744064 [label="mat1
 (156865, 384)" fillcolor=orange]
	139939050570176 -> 139938016745216 [dir=none]
	139938016745216 [label="mat2
 (384, 128)" fillcolor=orange]
	139939050570176 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :  (156865, 384)
mat1_strides:       (384, 1)
mat2        : [saved tensor]
mat2_sizes  :     (384, 128)
mat2_strides:       (1, 384)"]
	139939050573104 -> 139939050570176
	139936673414720 [label="model.lane2actor_attention.attention_layers.0.edge_encoder.0.bias
 (128)" fillcolor=lightblue]
	139936673414720 -> 139939050573104
	139939050573104 [label=AccumulateGrad]
	139939050569984 -> 139939050570176
	139939050569984 [label="CatBackward
-------------------------
dim: 18446744073709551615"]
	139939050571136 -> 139939050569984
	139939050571136 -> 139938016746688 [dir=none]
	139938016746688 [label="indices[0]
 (156865)" fillcolor=orange]
	139939050571136 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139939050572480 -> 139939050571136
	139939050572480 -> 139938016745856 [dir=none]
	139938016745856 [label="result
 (9921, 128)" fillcolor=orange]
	139939050572480 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139939050573248 -> 139939050572480
	139939050573248 -> 139938016747456 [dir=none]
	139938016747456 [label="mat1
 (9921, 128)" fillcolor=orange]
	139939050573248 -> 139938016747072 [dir=none]
	139938016747072 [label="mat2
 (128, 128)" fillcolor=orange]
	139939050573248 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (9921, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139939050573632 -> 139939050573248
	139936673412928 [label="model.lane2actor_attention.attention_layers.0.src_encoder.0.bias
 (128)" fillcolor=lightblue]
	139936673412928 -> 139939050573632
	139939050573632 [label=AccumulateGrad]
	139939050573440 -> 139939050573248
	139939050573440 -> 139936677535552 [dir=none]
	139936677535552 [label="result
 (9921, 128)" fillcolor=orange]
	139939050573440 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139939050570944 -> 139939050573440
	139939050570944 [label="AddBackward0
------------
alpha: 1"]
	139939050572672 -> 139939050570944
	139939050572672 -> 139936677532288 [dir=none]
	139936677532288 [label="mat1
 (9921, 128)" fillcolor=orange]
	139939050572672 -> 139936677532096 [dir=none]
	139936677532096 [label="mat2
 (128, 128)" fillcolor=orange]
	139939050572672 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (9921, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139938130436352 -> 139939050572672
	139936673412096 [label="model.actor2lane_attention.attention_layers.3.output_linear.bias
 (128)" fillcolor=lightblue]
	139936673412096 -> 139938130436352
	139938130436352 [label=AccumulateGrad]
	139938130436256 -> 139939050572672
	139938130436256 -> 139936677533568 [dir=none]
	139936677533568 [label="result
 (9921, 128)" fillcolor=orange]
	139938130436256 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139938130436640 -> 139938130436256
	139938130436640 -> 139936677532800 [dir=none]
	139936677532800 [label="bias
 (128)" fillcolor=orange]
	139938130436640 -> 139936677534080 [dir=none]
	139936677534080 [label="input
 (9921, 128)" fillcolor=orange]
	139938130436640 -> 139936677534464 [dir=none]
	139936677534464 [label="result1
 (9921, 1)" fillcolor=orange]
	139938130436640 -> 139936677535360 [dir=none]
	139936677535360 [label="result2
 (9921, 1)" fillcolor=orange]
	139938130436640 -> 139936677531904 [dir=none]
	139936677531904 [label="weight
 (128)" fillcolor=orange]
	139938130436640 [label="NativeLayerNormBackward
--------------------------------
bias            : [saved tensor]
eps             :          1e-05
input           : [saved tensor]
normalized_shape:         (128,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	139938130436928 -> 139938130436640
	139938130436928 -> 139936677535424 [dir=none]
	139936677535424 [label="index
 (156865)" fillcolor=orange]
	139938130436928 -> 139936677532544 [dir=none]
	139936677532544 [label="source
 (156865, 128)" fillcolor=orange]
	139938130436928 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139938130437312 -> 139938130436928
	139938130437312 [label=CloneBackward]
	139938130437504 -> 139938130437312
	139938130437504 -> 139936677533120 [dir=none]
	139936677533120 [label="result
 (9921, 128)" fillcolor=orange]
	139938130437504 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139938130437792 -> 139938130437504
	139938130437792 -> 139936677533952 [dir=none]
	139936677533952 [label="mat1
 (9921, 128)" fillcolor=orange]
	139938130437792 -> 139936677533696 [dir=none]
	139936677533696 [label="mat2
 (128, 128)" fillcolor=orange]
	139938130437792 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (9921, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139938130438080 -> 139938130437792
	139936673569600 [label="model.actor2lane_attention.attention_layers.3.dst_encoder.0.bias
 (128)" fillcolor=lightblue]
	139936673569600 -> 139938130438080
	139938130438080 [label=AccumulateGrad]
	139939050572288 -> 139938130437792
	139939050572288 -> 139936677534528 [dir=none]
	139936677534528 [label="result
 (9921, 128)" fillcolor=orange]
	139939050572288 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139938130438224 -> 139939050572288
	139938130438224 [label="AddBackward0
------------
alpha: 1"]
	139938130438944 -> 139938130438224
	139938130438944 -> 139936677535616 [dir=none]
	139936677535616 [label="mat1
 (9921, 128)" fillcolor=orange]
	139938130438944 -> 139936677532480 [dir=none]
	139936677532480 [label="mat2
 (128, 128)" fillcolor=orange]
	139938130438944 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (9921, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139938130439520 -> 139938130438944
	139936673568576 [label="model.actor2lane_attention.attention_layers.2.output_linear.bias
 (128)" fillcolor=lightblue]
	139936673568576 -> 139938130439520
	139938130439520 [label=AccumulateGrad]
	139938130439232 -> 139938130438944
	139938130439232 -> 139936677531968 [dir=none]
	139936677531968 [label="result
 (9921, 128)" fillcolor=orange]
	139938130439232 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139938130439760 -> 139938130439232
	139938130439760 -> 139936677534656 [dir=none]
	139936677534656 [label="bias
 (128)" fillcolor=orange]
	139938130439760 -> 139936677533248 [dir=none]
	139936677533248 [label="input
 (9921, 128)" fillcolor=orange]
	139938130439760 -> 139936677532928 [dir=none]
	139936677532928 [label="result1
 (9921, 1)" fillcolor=orange]
	139938130439760 -> 139936677534016 [dir=none]
	139936677534016 [label="result2
 (9921, 1)" fillcolor=orange]
	139938130439760 -> 139936677534976 [dir=none]
	139936677534976 [label="weight
 (128)" fillcolor=orange]
	139938130439760 [label="NativeLayerNormBackward
--------------------------------
bias            : [saved tensor]
eps             :          1e-05
input           : [saved tensor]
normalized_shape:         (128,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	139938130436304 -> 139938130439760
	139938130436304 -> 139936677533824 [dir=none]
	139936677533824 [label="index
 (156865)" fillcolor=orange]
	139938130436304 -> 139936677532736 [dir=none]
	139936677532736 [label="source
 (156865, 128)" fillcolor=orange]
	139938130436304 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139938130436592 -> 139938130436304
	139938130436592 [label=CloneBackward]
	139938130436976 -> 139938130436592
	139938130436976 -> 139936677535488 [dir=none]
	139936677535488 [label="result
 (9921, 128)" fillcolor=orange]
	139938130436976 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139938130437168 -> 139938130436976
	139938130437168 -> 139936677532608 [dir=none]
	139936677532608 [label="mat1
 (9921, 128)" fillcolor=orange]
	139938130437168 -> 139936677532032 [dir=none]
	139936677532032 [label="mat2
 (128, 128)" fillcolor=orange]
	139938130437168 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (9921, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139938130437456 -> 139938130437168
	139936673197696 [label="model.actor2lane_attention.attention_layers.2.dst_encoder.0.bias
 (128)" fillcolor=lightblue]
	139936673197696 -> 139938130437456
	139938130437456 [label=AccumulateGrad]
	139938130438800 -> 139938130437168
	139938130438800 -> 139936677534784 [dir=none]
	139936677534784 [label="result
 (9921, 128)" fillcolor=orange]
	139938130438800 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139938130437552 -> 139938130438800
	139938130437552 [label="AddBackward0
------------
alpha: 1"]
	139938130437984 -> 139938130437552
	139938130437984 -> 139936689763264 [dir=none]
	139936689763264 [label="mat1
 (9921, 128)" fillcolor=orange]
	139938130437984 -> 139936689764992 [dir=none]
	139936689764992 [label="mat2
 (128, 128)" fillcolor=orange]
	139938130437984 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (9921, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139938130438176 -> 139938130437984
	139936673196672 [label="model.actor2lane_attention.attention_layers.1.output_linear.bias
 (128)" fillcolor=lightblue]
	139936673196672 -> 139938130438176
	139938130438176 [label=AccumulateGrad]
	139938130438128 -> 139938130437984
	139938130438128 -> 139936689763776 [dir=none]
	139936689763776 [label="result
 (9921, 128)" fillcolor=orange]
	139938130438128 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139938130438320 -> 139938130438128
	139938130438320 -> 139936689764544 [dir=none]
	139936689764544 [label="bias
 (128)" fillcolor=orange]
	139938130438320 -> 139936689765376 [dir=none]
	139936689765376 [label="input
 (9921, 128)" fillcolor=orange]
	139938130438320 -> 139936689765760 [dir=none]
	139936689765760 [label="result1
 (9921, 1)" fillcolor=orange]
	139938130438320 -> 139936689763904 [dir=none]
	139936689763904 [label="result2
 (9921, 1)" fillcolor=orange]
	139938130438320 -> 139936689763520 [dir=none]
	139936689763520 [label="weight
 (128)" fillcolor=orange]
	139938130438320 [label="NativeLayerNormBackward
--------------------------------
bias            : [saved tensor]
eps             :          1e-05
input           : [saved tensor]
normalized_shape:         (128,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	139938130438704 -> 139938130438320
	139938130438704 -> 139936689762688 [dir=none]
	139936689762688 [label="index
 (156865)" fillcolor=orange]
	139938130438704 -> 139936689766208 [dir=none]
	139936689766208 [label="source
 (156865, 128)" fillcolor=orange]
	139938130438704 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139938130438992 -> 139938130438704
	139938130438992 [label=CloneBackward]
	139938130439184 -> 139938130438992
	139938130439184 -> 139936689764736 [dir=none]
	139936689764736 [label="result
 (9921, 128)" fillcolor=orange]
	139938130439184 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139938130439328 -> 139938130439184
	139938130439328 -> 139936689765312 [dir=none]
	139936689765312 [label="mat1
 (9921, 128)" fillcolor=orange]
	139938130439328 -> 139936689762560 [dir=none]
	139936689762560 [label="mat2
 (128, 128)" fillcolor=orange]
	139938130439328 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (9921, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139938130439424 -> 139938130439328
	139936673194496 [label="model.actor2lane_attention.attention_layers.1.dst_encoder.0.bias
 (128)" fillcolor=lightblue]
	139936673194496 -> 139938130439424
	139938130439424 [label=AccumulateGrad]
	139938130437840 -> 139938130439328
	139938130437840 -> 139936689766080 [dir=none]
	139936689766080 [label="result
 (9921, 128)" fillcolor=orange]
	139938130437840 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139938130439472 -> 139938130437840
	139938130439472 [label="AddBackward0
------------
alpha: 1"]
	139938130439856 -> 139938130439472
	139938130439856 -> 139936689763200 [dir=none]
	139936689763200 [label="mat1
 (9921, 128)" fillcolor=orange]
	139938130439856 -> 139936689765440 [dir=none]
	139936689765440 [label="mat2
 (128, 128)" fillcolor=orange]
	139938130439856 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (9921, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139938130440096 -> 139938130439856
	139936673353152 [label="model.actor2lane_attention.attention_layers.0.output_linear.bias
 (128)" fillcolor=lightblue]
	139936673353152 -> 139938130440096
	139938130440096 [label=AccumulateGrad]
	139938130440048 -> 139938130439856
	139938130440048 -> 139936689766336 [dir=none]
	139936689766336 [label="result
 (9921, 128)" fillcolor=orange]
	139938130440048 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139938312143008 -> 139938130440048
	139938312143008 -> 139936689763968 [dir=none]
	139936689763968 [label="bias
 (128)" fillcolor=orange]
	139938312143008 -> 139936689762496 [dir=none]
	139936689762496 [label="input
 (9921, 128)" fillcolor=orange]
	139938312143008 -> 139936689762880 [dir=none]
	139936689762880 [label="result1
 (9921, 1)" fillcolor=orange]
	139938312143008 -> 139936689763072 [dir=none]
	139936689763072 [label="result2
 (9921, 1)" fillcolor=orange]
	139938312143008 -> 139936689764672 [dir=none]
	139936689764672 [label="weight
 (128)" fillcolor=orange]
	139938312143008 [label="NativeLayerNormBackward
--------------------------------
bias            : [saved tensor]
eps             :          1e-05
input           : [saved tensor]
normalized_shape:         (128,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	139938312143344 -> 139938312143008
	139938312143344 -> 139936689766144 [dir=none]
	139936689766144 [label="index
 (156865)" fillcolor=orange]
	139938312143344 -> 139936689765248 [dir=none]
	139936689765248 [label="source
 (156865, 128)" fillcolor=orange]
	139938312143344 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139938312143728 -> 139938312143344
	139938312143728 [label=CloneBackward]
	139938312143968 -> 139938312143728
	139938312143968 -> 139936689764224 [dir=none]
	139936689764224 [label="result
 (9921, 128)" fillcolor=orange]
	139938312143968 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139938312144064 -> 139938312143968
	139938312144064 -> 139936689763008 [dir=none]
	139936689763008 [label="mat1
 (9921, 128)" fillcolor=orange]
	139938312144064 -> 139936689764416 [dir=none]
	139936689764416 [label="mat2
 (128, 128)" fillcolor=orange]
	139938312144064 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (9921, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139938312144256 -> 139938312144064
	139936673350976 [label="model.actor2lane_attention.attention_layers.0.dst_encoder.0.bias
 (128)" fillcolor=lightblue]
	139936673350976 -> 139938312144256
	139938312144256 [label=AccumulateGrad]
	139938130439712 -> 139938312144064
	139938130439712 -> 139936689763840 [dir=none]
	139936689763840 [label="input
 (9921, 128)" fillcolor=orange]
	139938130439712 -> 139936689766272 [dir=none]
	139936689766272 [label="result1
 (9921, 1)" fillcolor=orange]
	139938130439712 -> 139936689763648 [dir=none]
	139936689763648 [label="result2
 (9921, 1)" fillcolor=orange]
	139938130439712 -> 139936689764160 [dir=none]
	139936689764160 [label="weight
 (128)" fillcolor=orange]
	139938130439712 [label="NativeGroupNormBackward
-----------------------
C      :            128
HxW    :              1
N      :           9921
eps    :          1e-05
group  :              1
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	139938312144448 -> 139938130439712
	139938312144448 -> 139936682178496 [dir=none]
	139936682178496 [label="mat2
 (134, 128)" fillcolor=orange]
	139938312144448 -> 139936682177920 [dir=none]
	139936682177920 [label="self
 (9921, 134)" fillcolor=orange]
	139938312144448 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (134, 128)
mat2_strides:       (1, 134)
self        : [saved tensor]
self_sizes  :    (9921, 134)
self_strides:       (134, 1)"]
	139938312144976 -> 139938312144448
	139938312144976 [label="CatBackward
-----------
dim: 1"]
	139938312145264 -> 139938312144976
	139938312145264 -> 139936682178880 [dir=none]
	139936682178880 [label="result
 (9921, 128)" fillcolor=orange]
	139938312145264 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139938312145552 -> 139938312145264
	139938312145552 [label="AddBackward0
------------
alpha: 1"]
	139938312145744 -> 139938312145552
	139938312145744 -> 139936682178624 [dir=none]
	139936682178624 [label="input
 (9921, 128)" fillcolor=orange]
	139938312145744 -> 139936682176960 [dir=none]
	139936682176960 [label="result1
 (9921, 1)" fillcolor=orange]
	139938312145744 -> 139936682178112 [dir=none]
	139936682178112 [label="result2
 (9921, 1)" fillcolor=orange]
	139938312145744 -> 139936682177600 [dir=none]
	139936682177600 [label="weight
 (128)" fillcolor=orange]
	139938312145744 [label="NativeGroupNormBackward
-----------------------
C      :            128
HxW    :              1
N      :           9921
eps    :          1e-05
group  :              1
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	139938312145888 -> 139938312145744
	139938312145888 -> 139936682177216 [dir=none]
	139936682177216 [label="mat2
 (128, 128)" fillcolor=orange]
	139938312145888 -> 139936682178240 [dir=none]
	139936682178240 [label="self
 (9921, 128)" fillcolor=orange]
	139938312145888 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9921, 128)
self_strides:       (128, 1)"]
	139938312146416 -> 139938312145888
	139938312146416 -> 139936682179968 [dir=none]
	139936682179968 [label="result
 (9921, 128)" fillcolor=orange]
	139938312146416 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139938312146704 -> 139938312146416
	139938312146704 -> 139936682179200 [dir=none]
	139936682179200 [label="input
 (9921, 128)" fillcolor=orange]
	139938312146704 -> 139936682178560 [dir=none]
	139936682178560 [label="result1
 (9921, 1)" fillcolor=orange]
	139938312146704 -> 139936682179648 [dir=none]
	139936682179648 [label="result2
 (9921, 1)" fillcolor=orange]
	139938312146704 -> 139936682177344 [dir=none]
	139936682177344 [label="weight
 (128)" fillcolor=orange]
	139938312146704 [label="NativeGroupNormBackward
-----------------------
C      :            128
HxW    :              1
N      :           9921
eps    :          1e-05
group  :              1
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	139938312142960 -> 139938312146704
	139938312142960 -> 139936682176704 [dir=none]
	139936682176704 [label="index
 (9873)" fillcolor=orange]
	139938312142960 -> 139936682176640 [dir=none]
	139936682176640 [label="source
 (9873, 128)" fillcolor=orange]
	139938312142960 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139938312143680 -> 139938312142960
	139938312143680 -> 139936682176576 [dir=none]
	139936682176576 [label="index
 (9873)" fillcolor=orange]
	139938312143680 -> 139936682180224 [dir=none]
	139936682180224 [label="source
 (9873, 128)" fillcolor=orange]
	139938312143680 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139938312144304 -> 139938312143680
	139938312144304 -> 139936682180288 [dir=none]
	139936682180288 [label="index
 (9885)" fillcolor=orange]
	139938312144304 -> 139936682177856 [dir=none]
	139936682177856 [label="source
 (9885, 128)" fillcolor=orange]
	139938312144304 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139938312144640 -> 139938312144304
	139938312144640 -> 139936682179072 [dir=none]
	139936682179072 [label="index
 (9885)" fillcolor=orange]
	139938312144640 -> 139936682178176 [dir=none]
	139936682178176 [label="source
 (9885, 128)" fillcolor=orange]
	139938312144640 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139938312144928 -> 139938312144640
	139938312144928 -> 139936682179776 [dir=none]
	139936682179776 [label="index
 (9897)" fillcolor=orange]
	139938312144928 -> 139936682176768 [dir=none]
	139936682176768 [label="source
 (9897, 128)" fillcolor=orange]
	139938312144928 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139938312145312 -> 139938312144928
	139938312145312 -> 139936682180480 [dir=none]
	139936682180480 [label="index
 (9897)" fillcolor=orange]
	139938312145312 -> 139936682179136 [dir=none]
	139936682179136 [label="source
 (9897, 128)" fillcolor=orange]
	139938312145312 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139938312145600 -> 139938312145312
	139938312145600 -> 139936682179392 [dir=none]
	139936682179392 [label="index
 (9909)" fillcolor=orange]
	139938312145600 -> 139936682180160 [dir=none]
	139936682180160 [label="source
 (9909, 128)" fillcolor=orange]
	139938312145600 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139938312146176 -> 139938312145600
	139938312146176 -> 139936682179712 [dir=none]
	139936682179712 [label="index
 (9909)" fillcolor=orange]
	139938312146176 -> 139936682177408 [dir=none]
	139936682177408 [label="source
 (9909, 128)" fillcolor=orange]
	139938312146176 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139938312146464 -> 139938312146176
	139938312146464 -> 139936682177792 [dir=none]
	139936682177792 [label="mat2
 (128, 128)" fillcolor=orange]
	139938312146464 -> 139939057421952 [dir=none]
	139939057421952 [label="self
 (9921, 128)" fillcolor=orange]
	139938312146464 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9921, 128)
self_strides:       (128, 1)"]
	139938312145648 -> 139938312146464
	139938312145648 -> 139939057419584 [dir=none]
	139939057419584 [label="result
 (9921, 128)" fillcolor=orange]
	139938312145648 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139938312144592 -> 139938312145648
	139938312144592 [label="AddBackward0
------------
alpha: 1"]
	139938312145504 -> 139938312144592
	139938312145504 -> 139939057419200 [dir=none]
	139939057419200 [label="input
 (9921, 128)" fillcolor=orange]
	139938312145504 -> 139939057418944 [dir=none]
	139939057418944 [label="result1
 (9921, 1)" fillcolor=orange]
	139938312145504 -> 139939057418432 [dir=none]
	139939057418432 [label="result2
 (9921, 1)" fillcolor=orange]
	139938312145504 -> 139939057420736 [dir=none]
	139939057420736 [label="weight
 (128)" fillcolor=orange]
	139938312145504 [label="NativeGroupNormBackward
-----------------------
C      :            128
HxW    :              1
N      :           9921
eps    :          1e-05
group  :              1
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	139936681777424 -> 139938312145504
	139936681777424 -> 139939057422016 [dir=none]
	139939057422016 [label="mat2
 (128, 128)" fillcolor=orange]
	139936681777424 -> 139939057420096 [dir=none]
	139939057420096 [label="self
 (9921, 128)" fillcolor=orange]
	139936681777424 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9921, 128)
self_strides:       (128, 1)"]
	139936681775216 -> 139936681777424
	139936681775216 -> 139939057420224 [dir=none]
	139939057420224 [label="result
 (9921, 128)" fillcolor=orange]
	139936681775216 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936681775360 -> 139936681775216
	139936681775360 -> 139939057420480 [dir=none]
	139939057420480 [label="input
 (9921, 128)" fillcolor=orange]
	139936681775360 -> 139939057420160 [dir=none]
	139939057420160 [label="result1
 (9921, 1)" fillcolor=orange]
	139936681775360 -> 139939057419904 [dir=none]
	139939057419904 [label="result2
 (9921, 1)" fillcolor=orange]
	139936681775360 -> 139939057419072 [dir=none]
	139939057419072 [label="weight
 (128)" fillcolor=orange]
	139936681775360 [label="NativeGroupNormBackward
-----------------------
C      :            128
HxW    :              1
N      :           9921
eps    :          1e-05
group  :              1
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	139936681775504 -> 139936681775360
	139936681775504 -> 139939057421696 [dir=none]
	139939057421696 [label="index
 (9873)" fillcolor=orange]
	139936681775504 -> 139939057419776 [dir=none]
	139939057419776 [label="source
 (9873, 128)" fillcolor=orange]
	139936681775504 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139936681775696 -> 139936681775504
	139936681775696 -> 139939057419136 [dir=none]
	139939057419136 [label="index
 (9873)" fillcolor=orange]
	139936681775696 -> 139939057422144 [dir=none]
	139939057422144 [label="source
 (9873, 128)" fillcolor=orange]
	139936681775696 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139936681775888 -> 139936681775696
	139936681775888 -> 139939057422272 [dir=none]
	139939057422272 [label="index
 (9885)" fillcolor=orange]
	139936681775888 -> 139936721098880 [dir=none]
	139936721098880 [label="source
 (9885, 128)" fillcolor=orange]
	139936681775888 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139936681776080 -> 139936681775888
	139936681776080 -> 139939057418368 [dir=none]
	139939057418368 [label="index
 (9885)" fillcolor=orange]
	139936681776080 -> 139939057421184 [dir=none]
	139939057421184 [label="source
 (9885, 128)" fillcolor=orange]
	139936681776080 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139936681776224 -> 139936681776080
	139936681776224 -> 139939057421568 [dir=none]
	139939057421568 [label="index
 (9897)" fillcolor=orange]
	139936681776224 -> 139939057421632 [dir=none]
	139939057421632 [label="source
 (9897, 128)" fillcolor=orange]
	139936681776224 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139936681776416 -> 139936681776224
	139936681776416 -> 139939057421888 [dir=none]
	139939057421888 [label="index
 (9897)" fillcolor=orange]
	139936681776416 -> 139939057421440 [dir=none]
	139939057421440 [label="source
 (9897, 128)" fillcolor=orange]
	139936681776416 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139936681776560 -> 139936681776416
	139936681776560 -> 139939057420032 [dir=none]
	139939057420032 [label="index
 (9909)" fillcolor=orange]
	139936681776560 -> 139939057418816 [dir=none]
	139939057418816 [label="source
 (9909, 128)" fillcolor=orange]
	139936681776560 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139936681776704 -> 139936681776560
	139936681776704 -> 139939057420864 [dir=none]
	139939057420864 [label="index
 (9909)" fillcolor=orange]
	139936681776704 -> 139939057420800 [dir=none]
	139939057420800 [label="source
 (9909, 128)" fillcolor=orange]
	139936681776704 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139936681776896 -> 139936681776704
	139936681776896 -> 139939057420928 [dir=none]
	139939057420928 [label="mat2
 (128, 128)" fillcolor=orange]
	139936681776896 -> 139936677475392 [dir=none]
	139936677475392 [label="self
 (9921, 128)" fillcolor=orange]
	139936681776896 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9921, 128)
self_strides:       (128, 1)"]
	139938312146656 -> 139936681776896
	139938312146656 -> 139936677475136 [dir=none]
	139936677475136 [label="result
 (9921, 128)" fillcolor=orange]
	139938312146656 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936681777232 -> 139938312146656
	139936681777232 [label="AddBackward0
------------
alpha: 1"]
	139936681777328 -> 139936681777232
	139936681777328 -> 139936677476032 [dir=none]
	139936677476032 [label="input
 (9921, 128)" fillcolor=orange]
	139936681777328 -> 139936677474880 [dir=none]
	139936677474880 [label="result1
 (9921, 1)" fillcolor=orange]
	139936681777328 -> 139936677476800 [dir=none]
	139936677476800 [label="result2
 (9921, 1)" fillcolor=orange]
	139936681777328 -> 139936677478272 [dir=none]
	139936677478272 [label="weight
 (128)" fillcolor=orange]
	139936681777328 [label="NativeGroupNormBackward
-----------------------
C      :            128
HxW    :              1
N      :           9921
eps    :          1e-05
group  :              1
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	139936681777520 -> 139936681777328
	139936681777520 -> 139936677476480 [dir=none]
	139936677476480 [label="mat2
 (128, 128)" fillcolor=orange]
	139936681777520 -> 139936677475328 [dir=none]
	139936677475328 [label="self
 (9921, 128)" fillcolor=orange]
	139936681777520 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9921, 128)
self_strides:       (128, 1)"]
	139936681777808 -> 139936681777520
	139936681777808 -> 139936677474944 [dir=none]
	139936677474944 [label="result
 (9921, 128)" fillcolor=orange]
	139936681777808 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936681777952 -> 139936681777808
	139936681777952 -> 139936677475968 [dir=none]
	139936677475968 [label="input
 (9921, 128)" fillcolor=orange]
	139936681777952 -> 139936677477824 [dir=none]
	139936677477824 [label="result1
 (9921, 1)" fillcolor=orange]
	139936681777952 -> 139936677477184 [dir=none]
	139936677477184 [label="result2
 (9921, 1)" fillcolor=orange]
	139936681777952 -> 139936677478016 [dir=none]
	139936677478016 [label="weight
 (128)" fillcolor=orange]
	139936681777952 [label="NativeGroupNormBackward
-----------------------
C      :            128
HxW    :              1
N      :           9921
eps    :          1e-05
group  :              1
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	139936681778048 -> 139936681777952
	139936681778048 -> 139936677477120 [dir=none]
	139936677477120 [label="index
 (9873)" fillcolor=orange]
	139936681778048 -> 139936677477504 [dir=none]
	139936677477504 [label="source
 (9873, 128)" fillcolor=orange]
	139936681778048 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139936681778240 -> 139936681778048
	139936681778240 -> 139936677477056 [dir=none]
	139936677477056 [label="index
 (9873)" fillcolor=orange]
	139936681778240 -> 139938272419328 [dir=none]
	139938272419328 [label="source
 (9873, 128)" fillcolor=orange]
	139936681778240 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139936681778384 -> 139936681778240
	139936681778384 -> 139938272417408 [dir=none]
	139938272417408 [label="index
 (9885)" fillcolor=orange]
	139936681778384 -> 139938272418048 [dir=none]
	139938272418048 [label="source
 (9885, 128)" fillcolor=orange]
	139936681778384 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139936681778528 -> 139936681778384
	139936681778528 -> 139938272417216 [dir=none]
	139938272417216 [label="index
 (9885)" fillcolor=orange]
	139936681778528 -> 139938272416064 [dir=none]
	139938272416064 [label="source
 (9885, 128)" fillcolor=orange]
	139936681778528 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139936681778672 -> 139936681778528
	139936681778672 -> 139938272417600 [dir=none]
	139938272417600 [label="index
 (9897)" fillcolor=orange]
	139936681778672 -> 139938272419648 [dir=none]
	139938272419648 [label="source
 (9897, 128)" fillcolor=orange]
	139936681778672 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139936681778816 -> 139936681778672
	139936681778816 -> 139938272416000 [dir=none]
	139938272416000 [label="index
 (9897)" fillcolor=orange]
	139936681778816 -> 139938272419392 [dir=none]
	139938272419392 [label="source
 (9897, 128)" fillcolor=orange]
	139936681778816 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139936681778960 -> 139936681778816
	139936681778960 -> 139938272416512 [dir=none]
	139938272416512 [label="index
 (9909)" fillcolor=orange]
	139936681778960 -> 139938272416256 [dir=none]
	139938272416256 [label="source
 (9909, 128)" fillcolor=orange]
	139936681778960 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139936681779104 -> 139936681778960
	139936681779104 -> 139938272417984 [dir=none]
	139938272417984 [label="index
 (9909)" fillcolor=orange]
	139936681779104 -> 139938272415808 [dir=none]
	139938272415808 [label="source
 (9909, 128)" fillcolor=orange]
	139936681779104 [label="IndexAddBackward
--------------------------
alpha     :              1
dim       :              0
index     : [saved tensor]
source    : [saved tensor]
source_dim:              2"]
	139936681779152 -> 139936681779104
	139936681779152 -> 139938272419008 [dir=none]
	139938272419008 [label="mat2
 (128, 128)" fillcolor=orange]
	139936681779152 -> 139938272417728 [dir=none]
	139938272417728 [label="self
 (9921, 128)" fillcolor=orange]
	139936681779152 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9921, 128)
self_strides:       (128, 1)"]
	139936681777280 -> 139936681779152
	139936681777280 -> 139938272418880 [dir=none]
	139938272418880 [label="result
 (9921, 128)" fillcolor=orange]
	139936681777280 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139938269059584 -> 139936681777280
	139938269059584 [label="AddBackward0
------------
alpha: 1"]
	139938269060160 -> 139938269059584
	139938269060160 -> 139938272417280 [dir=none]
	139938272417280 [label="input
 (9921, 128)" fillcolor=orange]
	139938269060160 -> 139938272416576 [dir=none]
	139938272416576 [label="result1
 (9921, 1)" fillcolor=orange]
	139938269060160 -> 139938272416832 [dir=none]
	139938272416832 [label="result2
 (9921, 1)" fillcolor=orange]
	139938269060160 -> 139938272416960 [dir=none]
	139938272416960 [label="weight
 (128)" fillcolor=orange]
	139938269060160 [label="NativeGroupNormBackward
-----------------------
C      :            128
HxW    :              1
N      :           9921
eps    :          1e-05
group  :              1
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	139938269057136 -> 139938269060160
	139938269057136 -> 139936686386880 [dir=none]
	139936686386880 [label="mat2
 (128, 128)" fillcolor=orange]
	139938269057136 -> 139936686384512 [dir=none]
	139936686384512 [label="self
 (9921, 128)" fillcolor=orange]
	139938269057136 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9921, 128)
self_strides:       (128, 1)"]
	139938269057712 -> 139938269057136
	139938269057712 -> 139936686383616 [dir=none]
	139936686383616 [label="result
 (9921, 128)" fillcolor=orange]
	139938269057712 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139938269058000 -> 139938269057712
	139938269058000 -> 139938272416320 [dir=none]
	139938272416320 [label="mat1
 (9921, 2)" fillcolor=orange]
	139938269058000 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (9921, 2)
mat1_strides:             ()
mat2        :           None
mat2_sizes  :       (2, 128)
mat2_strides:         (1, 2)"]
	139938269058096 -> 139938269058000
	139936672084992 [label="model.lane_net.input.0.bias
 (128)" fillcolor=lightblue]
	139936672084992 -> 139938269058096
	139938269058096 [label=AccumulateGrad]
	139938269058048 -> 139938269058000
	139938269058048 [label=TBackward]
	139938269058144 -> 139938269058048
	139936672084800 [label="model.lane_net.input.0.weight
 (128, 2)" fillcolor=lightblue]
	139936672084800 -> 139938269058144
	139938269058144 [label=AccumulateGrad]
	139938269057568 -> 139938269057136
	139938269057568 [label=TBackward]
	139938269058288 -> 139938269057568
	139936672085056 [label="model.lane_net.input.2.linear.weight
 (128, 128)" fillcolor=lightblue]
	139936672085056 -> 139938269058288
	139938269058288 [label=AccumulateGrad]
	139938269061024 -> 139938269060160
	139936672085440 [label="model.lane_net.input.2.norm.weight
 (128)" fillcolor=lightblue]
	139936672085440 -> 139938269061024
	139938269061024 [label=AccumulateGrad]
	139938269060592 -> 139938269060160
	139936672085248 [label="model.lane_net.input.2.norm.bias
 (128)" fillcolor=lightblue]
	139936672085248 -> 139938269060592
	139938269060592 [label=AccumulateGrad]
	139938269059824 -> 139938269059584
	139938269059824 -> 139938272418496 [dir=none]
	139938272418496 [label="input
 (9921, 128)" fillcolor=orange]
	139938269059824 -> 139938272418944 [dir=none]
	139938272418944 [label="result1
 (9921, 1)" fillcolor=orange]
	139938269059824 -> 139938272416640 [dir=none]
	139938272416640 [label="result2
 (9921, 1)" fillcolor=orange]
	139938269059824 -> 139938272418560 [dir=none]
	139938272418560 [label="weight
 (128)" fillcolor=orange]
	139938269059824 [label="NativeGroupNormBackward
-----------------------
C      :            128
HxW    :              1
N      :           9921
eps    :          1e-05
group  :              1
input  : [saved tensor]
result1: [saved tensor]
result2: [saved tensor]
weight : [saved tensor]"]
	139938269057760 -> 139938269059824
	139938269057760 -> 139938272418368 [dir=none]
	139938272418368 [label="mat2
 (128, 128)" fillcolor=orange]
	139938269057760 -> 139938272416896 [dir=none]
	139938272416896 [label="self
 (9921, 128)" fillcolor=orange]
	139938269057760 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9921, 128)
self_strides:       (128, 1)"]
	139938269058576 -> 139938269057760
	139938269058576 -> 139938272418240 [dir=none]
	139938272418240 [label="result
 (9921, 128)" fillcolor=orange]
	139938269058576 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139938269059008 -> 139938269058576
	139938269059008 -> 139938272419584 [dir=none]
	139938272419584 [label="mat1
 (9921, 2)" fillcolor=orange]
	139938269059008 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (9921, 2)
mat1_strides:             ()
mat2        :           None
mat2_sizes  :       (2, 128)
mat2_strides:         (1, 2)"]
	139938269059152 -> 139938269059008
	139936672087296 [label="model.lane_net._seg.0.bias
 (128)" fillcolor=lightblue]
	139936672087296 -> 139938269059152
	139938269059152 [label=AccumulateGrad]
	139938269059104 -> 139938269059008
	139938269059104 [label=TBackward]
	139938269059296 -> 139938269059104
	139936672087104 [label="model.lane_net._seg.0.weight
 (128, 2)" fillcolor=lightblue]
	139936672087104 -> 139938269059296
	139938269059296 [label=AccumulateGrad]
	139938269057808 -> 139938269057760
	139938269057808 [label=TBackward]
	139938269059440 -> 139938269057808
	139936672087744 [label="model.lane_net._seg.2.linear.weight
 (128, 128)" fillcolor=lightblue]
	139936672087744 -> 139938269059440
	139938269059440 [label=AccumulateGrad]
	139938269057424 -> 139938269059824
	139936672087808 [label="model.lane_net._seg.2.norm.weight
 (128)" fillcolor=lightblue]
	139936672087808 -> 139938269057424
	139938269057424 [label=AccumulateGrad]
	139938269057232 -> 139938269059824
	139936672424000 [label="model.lane_net._seg.2.norm.bias
 (128)" fillcolor=lightblue]
	139936672424000 -> 139938269057232
	139938269057232 [label=AccumulateGrad]
	139938269058864 -> 139936681779152
	139938269058864 [label=TBackward]
	139938269058672 -> 139938269058864
	139936672425152 [label="model.lane_net.fusion_net.center.0.weight
 (128, 128)" fillcolor=lightblue]
	139936672425152 -> 139938269058672
	139938269058672 [label=AccumulateGrad]
	139938269057376 -> 139936681779104
	139938269057376 -> 139938272418624 [dir=none]
	139938272418624 [label="mat2
 (128, 128)" fillcolor=orange]
	139938269057376 -> 139938272419712 [dir=none]
	139938272419712 [label="self
 (9909, 128)" fillcolor=orange]
	139938269057376 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9909, 128)
self_strides:       (128, 1)"]
	139938269058768 -> 139938269057376
	139938269058768 -> 139938272419136 [dir=none]
	139938272419136 [label="indices[0]
 (9909)" fillcolor=orange]
	139938269058768 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139936681777280 -> 139938269058768
	139938269057520 -> 139938269057376
	139938269057520 [label=TBackward]
	139938269058720 -> 139938269057520
	139936672426176 [label="model.lane_net.fusion_net.pre1.0.weight
 (128, 128)" fillcolor=lightblue]
	139936672426176 -> 139938269058720
	139938269058720 [label=AccumulateGrad]
	139936681779056 -> 139936681778960
	139936681779056 -> 139936681483136 [dir=none]
	139936681483136 [label="mat2
 (128, 128)" fillcolor=orange]
	139936681779056 -> 139936681480768 [dir=none]
	139936681480768 [label="self
 (9909, 128)" fillcolor=orange]
	139936681779056 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9909, 128)
self_strides:       (128, 1)"]
	139938269059200 -> 139936681779056
	139938269059200 -> 139936681482880 [dir=none]
	139936681482880 [label="indices[0]
 (9909)" fillcolor=orange]
	139938269059200 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139936681777280 -> 139938269059200
	139938269057616 -> 139936681779056
	139938269057616 [label=TBackward]
	139938269058960 -> 139938269057616
	139936672426240 [label="model.lane_net.fusion_net.suc1.0.weight
 (128, 128)" fillcolor=lightblue]
	139936672426240 -> 139938269058960
	139938269058960 [label=AccumulateGrad]
	139936681778912 -> 139936681778816
	139936681778912 -> 139936681481280 [dir=none]
	139936681481280 [label="mat2
 (128, 128)" fillcolor=orange]
	139936681778912 -> 139936681482688 [dir=none]
	139936681482688 [label="self
 (9897, 128)" fillcolor=orange]
	139936681778912 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9897, 128)
self_strides:       (128, 1)"]
	139936681779008 -> 139936681778912
	139936681779008 -> 139936681482624 [dir=none]
	139936681482624 [label="indices[0]
 (9897)" fillcolor=orange]
	139936681779008 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139936681777280 -> 139936681779008
	139938269059728 -> 139936681778912
	139938269059728 [label=TBackward]
	139938269059872 -> 139938269059728
	139936672426304 [label="model.lane_net.fusion_net.pre2.0.weight
 (128, 128)" fillcolor=lightblue]
	139936672426304 -> 139938269059872
	139938269059872 [label=AccumulateGrad]
	139936681778768 -> 139936681778672
	139936681778768 -> 139936681481728 [dir=none]
	139936681481728 [label="mat2
 (128, 128)" fillcolor=orange]
	139936681778768 -> 139936681481536 [dir=none]
	139936681481536 [label="self
 (9897, 128)" fillcolor=orange]
	139936681778768 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9897, 128)
self_strides:       (128, 1)"]
	139936681778864 -> 139936681778768
	139936681778864 -> 139936681481216 [dir=none]
	139936681481216 [label="indices[0]
 (9897)" fillcolor=orange]
	139936681778864 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139936681777280 -> 139936681778864
	139938269059632 -> 139936681778768
	139938269059632 [label=TBackward]
	139938269060112 -> 139938269059632
	139936672426432 [label="model.lane_net.fusion_net.suc2.0.weight
 (128, 128)" fillcolor=lightblue]
	139936672426432 -> 139938269060112
	139938269060112 [label=AccumulateGrad]
	139936681778624 -> 139936681778528
	139936681778624 -> 139936681482240 [dir=none]
	139936681482240 [label="mat2
 (128, 128)" fillcolor=orange]
	139936681778624 -> 139936681483328 [dir=none]
	139936681483328 [label="self
 (9885, 128)" fillcolor=orange]
	139936681778624 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9885, 128)
self_strides:       (128, 1)"]
	139936681778720 -> 139936681778624
	139936681778720 -> 139936681481344 [dir=none]
	139936681481344 [label="indices[0]
 (9885)" fillcolor=orange]
	139936681778720 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139936681777280 -> 139936681778720
	139938269060016 -> 139936681778624
	139938269060016 [label=TBackward]
	139938269060304 -> 139938269060016
	139936672426624 [label="model.lane_net.fusion_net.pre3.0.weight
 (128, 128)" fillcolor=lightblue]
	139936672426624 -> 139938269060304
	139938269060304 [label=AccumulateGrad]
	139936681778480 -> 139936681778384
	139936681778480 -> 139936681484032 [dir=none]
	139936681484032 [label="mat2
 (128, 128)" fillcolor=orange]
	139936681778480 -> 139936681480704 [dir=none]
	139936681480704 [label="self
 (9885, 128)" fillcolor=orange]
	139936681778480 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9885, 128)
self_strides:       (128, 1)"]
	139936681778576 -> 139936681778480
	139936681778576 -> 139936681481920 [dir=none]
	139936681481920 [label="indices[0]
 (9885)" fillcolor=orange]
	139936681778576 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139936681777280 -> 139936681778576
	139938269060256 -> 139936681778480
	139938269060256 [label=TBackward]
	139938269060448 -> 139938269060256
	139936672426816 [label="model.lane_net.fusion_net.suc3.0.weight
 (128, 128)" fillcolor=lightblue]
	139936672426816 -> 139938269060448
	139938269060448 [label=AccumulateGrad]
	139936681778336 -> 139936681778240
	139936681778336 -> 139936681483584 [dir=none]
	139936681483584 [label="mat2
 (128, 128)" fillcolor=orange]
	139936681778336 -> 139936681482432 [dir=none]
	139936681482432 [label="self
 (9873, 128)" fillcolor=orange]
	139936681778336 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9873, 128)
self_strides:       (128, 1)"]
	139936681778432 -> 139936681778336
	139936681778432 -> 139936681481984 [dir=none]
	139936681481984 [label="indices[0]
 (9873)" fillcolor=orange]
	139936681778432 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139936681777280 -> 139936681778432
	139938269060400 -> 139936681778336
	139938269060400 [label=TBackward]
	139938269060640 -> 139938269060400
	139936672427008 [label="model.lane_net.fusion_net.pre4.0.weight
 (128, 128)" fillcolor=lightblue]
	139936672427008 -> 139938269060640
	139938269060640 [label=AccumulateGrad]
	139936681778192 -> 139936681778048
	139936681778192 -> 139936681483264 [dir=none]
	139936681483264 [label="mat2
 (128, 128)" fillcolor=orange]
	139936681778192 -> 139936681481600 [dir=none]
	139936681481600 [label="self
 (9873, 128)" fillcolor=orange]
	139936681778192 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9873, 128)
self_strides:       (128, 1)"]
	139936681778288 -> 139936681778192
	139936681778288 -> 139936681482752 [dir=none]
	139936681482752 [label="indices[0]
 (9873)" fillcolor=orange]
	139936681778288 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139936681777280 -> 139936681778288
	139938269060496 -> 139936681778192
	139938269060496 [label=TBackward]
	139938269060784 -> 139938269060496
	139936672427200 [label="model.lane_net.fusion_net.suc4.0.weight
 (128, 128)" fillcolor=lightblue]
	139936672427200 -> 139938269060784
	139938269060784 [label=AccumulateGrad]
	139936681778000 -> 139936681777952
	139936672425088 [label="model.lane_net.fusion_net.group_norm.0.weight
 (128)" fillcolor=lightblue]
	139936672425088 -> 139936681778000
	139936681778000 [label=AccumulateGrad]
	139936681777856 -> 139936681777952
	139936672425344 [label="model.lane_net.fusion_net.group_norm.0.bias
 (128)" fillcolor=lightblue]
	139936672425344 -> 139936681777856
	139936681777856 [label=AccumulateGrad]
	139936681777664 -> 139936681777520
	139936681777664 [label=TBackward]
	139936681778144 -> 139936681777664
	139936672425728 [label="model.lane_net.fusion_net.linear_w_group_norm.0.linear.weight
 (128, 128)" fillcolor=lightblue]
	139936672425728 -> 139936681778144
	139936681778144 [label=AccumulateGrad]
	139936681777472 -> 139936681777328
	139936672425792 [label="model.lane_net.fusion_net.linear_w_group_norm.0.norm.weight
 (128)" fillcolor=lightblue]
	139936672425792 -> 139936681777472
	139936681777472 [label=AccumulateGrad]
	139936681777376 -> 139936681777328
	139936672426048 [label="model.lane_net.fusion_net.linear_w_group_norm.0.norm.bias
 (128)" fillcolor=lightblue]
	139936672426048 -> 139936681777376
	139936681777376 [label=AccumulateGrad]
	139936681777280 -> 139936681777232
	139936681777088 -> 139936681776896
	139936681777088 [label=TBackward]
	139936681777568 -> 139936681777088
	139936672427392 [label="model.lane_net.fusion_net.center.1.weight
 (128, 128)" fillcolor=lightblue]
	139936672427392 -> 139936681777568
	139936681777568 [label=AccumulateGrad]
	139936681776848 -> 139936681776704
	139936681776848 -> 139936681480832 [dir=none]
	139936681480832 [label="mat2
 (128, 128)" fillcolor=orange]
	139936681776848 -> 139936681482368 [dir=none]
	139936681482368 [label="self
 (9909, 128)" fillcolor=orange]
	139936681776848 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9909, 128)
self_strides:       (128, 1)"]
	139936681778096 -> 139936681776848
	139936681778096 -> 139936681480576 [dir=none]
	139936681480576 [label="indices[0]
 (9909)" fillcolor=orange]
	139936681778096 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139938312146656 -> 139936681778096
	139936681776944 -> 139936681776848
	139936681776944 [label=TBackward]
	139936681777616 -> 139936681776944
	139936672809792 [label="model.lane_net.fusion_net.pre1.1.weight
 (128, 128)" fillcolor=lightblue]
	139936672809792 -> 139936681777616
	139936681777616 [label=AccumulateGrad]
	139936681776656 -> 139936681776560
	139936681776656 -> 139936681482304 [dir=none]
	139936681482304 [label="mat2
 (128, 128)" fillcolor=orange]
	139936681776656 -> 139936681484224 [dir=none]
	139936681484224 [label="self
 (9909, 128)" fillcolor=orange]
	139936681776656 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9909, 128)
self_strides:       (128, 1)"]
	139936681777184 -> 139936681776656
	139936681777184 -> 139936681483648 [dir=none]
	139936681483648 [label="indices[0]
 (9909)" fillcolor=orange]
	139936681777184 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139938312146656 -> 139936681777184
	139936681776992 -> 139936681776656
	139936681776992 [label=TBackward]
	139936681777904 -> 139936681776992
	139936672809856 [label="model.lane_net.fusion_net.suc1.1.weight
 (128, 128)" fillcolor=lightblue]
	139936672809856 -> 139936681777904
	139936681777904 [label=AccumulateGrad]
	139936681776512 -> 139936681776416
	139936681776512 -> 139936681480512 [dir=none]
	139936681480512 [label="mat2
 (128, 128)" fillcolor=orange]
	139936681776512 -> 139936681483776 [dir=none]
	139936681483776 [label="self
 (9897, 128)" fillcolor=orange]
	139936681776512 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9897, 128)
self_strides:       (128, 1)"]
	139936681776800 -> 139936681776512
	139936681776800 -> 139936677153664 [dir=none]
	139936677153664 [label="indices[0]
 (9897)" fillcolor=orange]
	139936681776800 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139938312146656 -> 139936681776800
	139936681776608 -> 139936681776512
	139936681776608 [label=TBackward]
	139938269060880 -> 139936681776608
	139936672809920 [label="model.lane_net.fusion_net.pre2.1.weight
 (128, 128)" fillcolor=lightblue]
	139936672809920 -> 139938269060880
	139938269060880 [label=AccumulateGrad]
	139936681776368 -> 139936681776224
	139936681776368 -> 139936677154176 [dir=none]
	139936677154176 [label="mat2
 (128, 128)" fillcolor=orange]
	139936681776368 -> 139936677153600 [dir=none]
	139936677153600 [label="self
 (9897, 128)" fillcolor=orange]
	139936681776368 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9897, 128)
self_strides:       (128, 1)"]
	139936681776464 -> 139936681776368
	139936681776464 -> 139936677154560 [dir=none]
	139936677154560 [label="indices[0]
 (9897)" fillcolor=orange]
	139936681776464 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139938312146656 -> 139936681776464
	139938269059248 -> 139936681776368
	139938269059248 [label=TBackward]
	139938269059680 -> 139938269059248
	139936672810048 [label="model.lane_net.fusion_net.suc2.1.weight
 (128, 128)" fillcolor=lightblue]
	139936672810048 -> 139938269059680
	139938269059680 [label=AccumulateGrad]
	139936681776176 -> 139936681776080
	139936681776176 -> 139936677153408 [dir=none]
	139936677153408 [label="mat2
 (128, 128)" fillcolor=orange]
	139936681776176 -> 139936677154624 [dir=none]
	139936677154624 [label="self
 (9885, 128)" fillcolor=orange]
	139936681776176 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9885, 128)
self_strides:       (128, 1)"]
	139938269060688 -> 139936681776176
	139938269060688 -> 139936677152256 [dir=none]
	139936677152256 [label="indices[0]
 (9885)" fillcolor=orange]
	139938269060688 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139938312146656 -> 139938269060688
	139938269057088 -> 139936681776176
	139938269057088 [label=TBackward]
	139936692265408 -> 139938269057088
	139936672810240 [label="model.lane_net.fusion_net.pre3.1.weight
 (128, 128)" fillcolor=lightblue]
	139936672810240 -> 139936692265408
	139936692265408 [label=AccumulateGrad]
	139936681775984 -> 139936681775888
	139936681775984 -> 139936677153984 [dir=none]
	139936677153984 [label="mat2
 (128, 128)" fillcolor=orange]
	139936681775984 -> 139936677153344 [dir=none]
	139936677153344 [label="self
 (9885, 128)" fillcolor=orange]
	139936681775984 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9885, 128)
self_strides:       (128, 1)"]
	139936681776320 -> 139936681775984
	139936681776320 -> 139936677153152 [dir=none]
	139936677153152 [label="indices[0]
 (9885)" fillcolor=orange]
	139936681776320 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139938312146656 -> 139936681776320
	139936681776128 -> 139936681775984
	139936681776128 [label=TBackward]
	139936692266368 -> 139936681776128
	139936672810432 [label="model.lane_net.fusion_net.suc3.1.weight
 (128, 128)" fillcolor=lightblue]
	139936672810432 -> 139936692266368
	139936692266368 [label=AccumulateGrad]
	139936681775792 -> 139936681775696
	139936681775792 -> 139936677154304 [dir=none]
	139936677154304 [label="mat2
 (128, 128)" fillcolor=orange]
	139936681775792 -> 139936677152512 [dir=none]
	139936677152512 [label="self
 (9873, 128)" fillcolor=orange]
	139936681775792 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9873, 128)
self_strides:       (128, 1)"]
	139936681775936 -> 139936681775792
	139936681775936 -> 139937997111872 [dir=none]
	139937997111872 [label="indices[0]
 (9873)" fillcolor=orange]
	139936681775936 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139938312146656 -> 139936681775936
	139936692265888 -> 139936681775792
	139936692265888 [label=TBackward]
	139936692267136 -> 139936692265888
	139936672810624 [label="model.lane_net.fusion_net.pre4.1.weight
 (128, 128)" fillcolor=lightblue]
	139936672810624 -> 139936692267136
	139936692267136 [label=AccumulateGrad]
	139936681775648 -> 139936681775504
	139936681775648 -> 139937997111552 [dir=none]
	139937997111552 [label="mat2
 (128, 128)" fillcolor=orange]
	139936681775648 -> 139937997112768 [dir=none]
	139937997112768 [label="self
 (9873, 128)" fillcolor=orange]
	139936681775648 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9873, 128)
self_strides:       (128, 1)"]
	139936681775744 -> 139936681775648
	139936681775744 -> 139937997114176 [dir=none]
	139937997114176 [label="indices[0]
 (9873)" fillcolor=orange]
	139936681775744 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139938312146656 -> 139936681775744
	139936692266608 -> 139936681775648
	139936692266608 [label=TBackward]
	139936692267904 -> 139936692266608
	139936672810816 [label="model.lane_net.fusion_net.suc4.1.weight
 (128, 128)" fillcolor=lightblue]
	139936672810816 -> 139936692267904
	139936692267904 [label=AccumulateGrad]
	139936681775408 -> 139936681775360
	139936672427584 [label="model.lane_net.fusion_net.group_norm.1.weight
 (128)" fillcolor=lightblue]
	139936672427584 -> 139936681775408
	139936681775408 [label=AccumulateGrad]
	139936681775264 -> 139936681775360
	139936672809088 [label="model.lane_net.fusion_net.group_norm.1.bias
 (128)" fillcolor=lightblue]
	139936672809088 -> 139936681775264
	139936681775264 [label=AccumulateGrad]
	139936681775168 -> 139936681777424
	139936681775168 [label=TBackward]
	139936681775600 -> 139936681775168
	139936672809344 [label="model.lane_net.fusion_net.linear_w_group_norm.1.linear.weight
 (128, 128)" fillcolor=lightblue]
	139936672809344 -> 139936681775600
	139936681775600 [label=AccumulateGrad]
	139936681777136 -> 139938312145504
	139936672809408 [label="model.lane_net.fusion_net.linear_w_group_norm.1.norm.weight
 (128)" fillcolor=lightblue]
	139936672809408 -> 139936681777136
	139936681777136 [label=AccumulateGrad]
	139936681777040 -> 139938312145504
	139936672809664 [label="model.lane_net.fusion_net.linear_w_group_norm.1.norm.bias
 (128)" fillcolor=lightblue]
	139936672809664 -> 139936681777040
	139936681777040 [label=AccumulateGrad]
	139938312146656 -> 139938312144592
	139938312146848 -> 139938312146464
	139938312146848 [label=TBackward]
	139938312143872 -> 139938312146848
	139936672811008 [label="model.lane_net.fusion_net.center.2.weight
 (128, 128)" fillcolor=lightblue]
	139936672811008 -> 139938312143872
	139938312143872 [label=AccumulateGrad]
	139938312146368 -> 139938312146176
	139938312146368 -> 139937997113024 [dir=none]
	139937997113024 [label="mat2
 (128, 128)" fillcolor=orange]
	139938312146368 -> 139937997114112 [dir=none]
	139937997114112 [label="self
 (9909, 128)" fillcolor=orange]
	139938312146368 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9909, 128)
self_strides:       (128, 1)"]
	139938312146752 -> 139938312146368
	139938312146752 -> 139937997111616 [dir=none]
	139937997111616 [label="indices[0]
 (9909)" fillcolor=orange]
	139938312146752 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139938312145648 -> 139938312146752
	139936681775552 -> 139938312146368
	139936681775552 [label=TBackward]
	139936681777760 -> 139936681775552
	139936672812416 [label="model.lane_net.fusion_net.pre1.2.weight
 (128, 128)" fillcolor=lightblue]
	139936672812416 -> 139936681777760
	139936681777760 [label=AccumulateGrad]
	139938312145936 -> 139938312145600
	139938312145936 -> 139937997113536 [dir=none]
	139937997113536 [label="mat2
 (128, 128)" fillcolor=orange]
	139938312145936 -> 139937997112256 [dir=none]
	139937997112256 [label="self
 (9909, 128)" fillcolor=orange]
	139938312145936 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9909, 128)
self_strides:       (128, 1)"]
	139938312146224 -> 139938312145936
	139938312146224 -> 139937997114304 [dir=none]
	139937997114304 [label="indices[0]
 (9909)" fillcolor=orange]
	139938312146224 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139938312145648 -> 139938312146224
	139936681776752 -> 139938312145936
	139936681776752 [label=TBackward]
	139936681775312 -> 139936681776752
	139936672812480 [label="model.lane_net.fusion_net.suc1.2.weight
 (128, 128)" fillcolor=lightblue]
	139936672812480 -> 139936681775312
	139936681775312 [label=AccumulateGrad]
	139938312145456 -> 139938312145312
	139938312145456 -> 139937997115008 [dir=none]
	139937997115008 [label="mat2
 (128, 128)" fillcolor=orange]
	139938312145456 -> 139937997114752 [dir=none]
	139937997114752 [label="self
 (9897, 128)" fillcolor=orange]
	139938312145456 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9897, 128)
self_strides:       (128, 1)"]
	139936681777712 -> 139938312145456
	139936681777712 -> 139937997111680 [dir=none]
	139937997111680 [label="indices[0]
 (9897)" fillcolor=orange]
	139936681777712 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139938312145648 -> 139936681777712
	139938312145696 -> 139938312145456
	139938312145696 [label=TBackward]
	139936692268096 -> 139938312145696
	139936672812544 [label="model.lane_net.fusion_net.pre2.2.weight
 (128, 128)" fillcolor=lightblue]
	139936672812544 -> 139936692268096
	139936692268096 [label=AccumulateGrad]
	139938312145216 -> 139938312144928
	139938312145216 -> 139937997114688 [dir=none]
	139937997114688 [label="mat2
 (128, 128)" fillcolor=orange]
	139938312145216 -> 139937997113664 [dir=none]
	139937997113664 [label="self
 (9897, 128)" fillcolor=orange]
	139938312145216 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9897, 128)
self_strides:       (128, 1)"]
	139938312145360 -> 139938312145216
	139938312145360 -> 139937997112064 [dir=none]
	139937997112064 [label="indices[0]
 (9897)" fillcolor=orange]
	139938312145360 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139938312145648 -> 139938312145360
	139936692268144 -> 139938312145216
	139936692268144 [label=TBackward]
	139936692268480 -> 139936692268144
	139936672812672 [label="model.lane_net.fusion_net.suc2.2.weight
 (128, 128)" fillcolor=lightblue]
	139936672812672 -> 139936692268480
	139936692268480 [label=AccumulateGrad]
	139938312144880 -> 139938312144640
	139938312144880 -> 139937997112512 [dir=none]
	139937997112512 [label="mat2
 (128, 128)" fillcolor=orange]
	139938312144880 -> 139937997112704 [dir=none]
	139937997112704 [label="self
 (9885, 128)" fillcolor=orange]
	139938312144880 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9885, 128)
self_strides:       (128, 1)"]
	139938312145120 -> 139938312144880
	139938312145120 -> 139937997114048 [dir=none]
	139937997114048 [label="indices[0]
 (9885)" fillcolor=orange]
	139938312145120 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139938312145648 -> 139938312145120
	139936692265168 -> 139938312144880
	139936692265168 [label=TBackward]
	139936692265984 -> 139936692265168
	139936672632896 [label="model.lane_net.fusion_net.pre3.2.weight
 (128, 128)" fillcolor=lightblue]
	139936672632896 -> 139936692265984
	139936692265984 [label=AccumulateGrad]
	139938312144400 -> 139938312144304
	139938312144400 -> 139937997115264 [dir=none]
	139937997115264 [label="mat2
 (128, 128)" fillcolor=orange]
	139938312144400 -> 139937997113408 [dir=none]
	139937997113408 [label="self
 (9885, 128)" fillcolor=orange]
	139938312144400 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9885, 128)
self_strides:       (128, 1)"]
	139938312144832 -> 139938312144400
	139938312144832 -> 139937997114496 [dir=none]
	139937997114496 [label="indices[0]
 (9885)" fillcolor=orange]
	139938312144832 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139938312145648 -> 139938312144832
	139936692265792 -> 139938312144400
	139936692265792 [label=TBackward]
	139936692266752 -> 139936692265792
	139936672633088 [label="model.lane_net.fusion_net.suc3.2.weight
 (128, 128)" fillcolor=lightblue]
	139936672633088 -> 139936692266752
	139936692266752 [label=AccumulateGrad]
	139938312144160 -> 139938312143680
	139938312144160 -> 139937997111360 [dir=none]
	139937997111360 [label="mat2
 (128, 128)" fillcolor=orange]
	139938312144160 -> 139937997113856 [dir=none]
	139937997113856 [label="self
 (9873, 128)" fillcolor=orange]
	139938312144160 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9873, 128)
self_strides:       (128, 1)"]
	139938312144352 -> 139938312144160
	139938312144352 -> 139937997114240 [dir=none]
	139937997114240 [label="indices[0]
 (9873)" fillcolor=orange]
	139938312144352 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139938312145648 -> 139938312144352
	139936692266560 -> 139938312144160
	139936692266560 [label=TBackward]
	139936692268288 -> 139936692266560
	139936672633280 [label="model.lane_net.fusion_net.pre4.2.weight
 (128, 128)" fillcolor=lightblue]
	139936672633280 -> 139936692268288
	139936692268288 [label=AccumulateGrad]
	139938312143392 -> 139938312142960
	139938312143392 -> 139937997112832 [dir=none]
	139937997112832 [label="mat2
 (128, 128)" fillcolor=orange]
	139938312143392 -> 139939054452864 [dir=none]
	139939054452864 [label="self
 (9873, 128)" fillcolor=orange]
	139938312143392 [label="MmBackward
----------------------------
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)
self        : [saved tensor]
self_sizes  :    (9873, 128)
self_strides:       (128, 1)"]
	139938312143920 -> 139938312143392
	139938312143920 -> 139939054453888 [dir=none]
	139939054453888 [label="indices[0]
 (9873)" fillcolor=orange]
	139938312143920 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139938312145648 -> 139938312143920
	139936692267328 -> 139938312143392
	139936692267328 [label=TBackward]
	139936692265600 -> 139936692267328
	139936672633472 [label="model.lane_net.fusion_net.suc4.2.weight
 (128, 128)" fillcolor=lightblue]
	139936672633472 -> 139936692265600
	139936692265600 [label=AccumulateGrad]
	139938312146896 -> 139938312146704
	139936672811200 [label="model.lane_net.fusion_net.group_norm.2.weight
 (128)" fillcolor=lightblue]
	139936672811200 -> 139938312146896
	139938312146896 [label=AccumulateGrad]
	139938312146560 -> 139938312146704
	139936672811584 [label="model.lane_net.fusion_net.group_norm.2.bias
 (128)" fillcolor=lightblue]
	139936672811584 -> 139938312146560
	139938312146560 [label=AccumulateGrad]
	139938312146272 -> 139938312145888
	139938312146272 [label=TBackward]
	139938312143296 -> 139938312146272
	139936672811968 [label="model.lane_net.fusion_net.linear_w_group_norm.2.linear.weight
 (128, 128)" fillcolor=lightblue]
	139936672811968 -> 139938312143296
	139938312143296 [label=AccumulateGrad]
	139938312145840 -> 139938312145744
	139936672812032 [label="model.lane_net.fusion_net.linear_w_group_norm.2.norm.weight
 (128)" fillcolor=lightblue]
	139936672812032 -> 139938312145840
	139938312145840 [label=AccumulateGrad]
	139938312145792 -> 139938312145744
	139936672812288 [label="model.lane_net.fusion_net.linear_w_group_norm.2.norm.bias
 (128)" fillcolor=lightblue]
	139936672812288 -> 139938312145792
	139938312145792 [label=AccumulateGrad]
	139938312145648 -> 139938312145552
	139938312144784 -> 139938312144448
	139938312144784 [label=TBackward]
	139938312145024 -> 139938312144784
	139936673349696 [label="model.actor2lane_attention.lane_meta.linear.weight
 (128, 134)" fillcolor=lightblue]
	139936673349696 -> 139938312145024
	139938312145024 [label=AccumulateGrad]
	139938312144496 -> 139938130439712
	139936673349760 [label="model.actor2lane_attention.lane_meta.norm.weight
 (128)" fillcolor=lightblue]
	139936673349760 -> 139938312144496
	139938312144496 [label=AccumulateGrad]
	139938312144544 -> 139938130439712
	139936673350016 [label="model.actor2lane_attention.lane_meta.norm.bias
 (128)" fillcolor=lightblue]
	139936673350016 -> 139938312144544
	139938312144544 [label=AccumulateGrad]
	139938312144208 -> 139938312144064
	139938312144208 [label=TBackward]
	139938312145408 -> 139938312144208
	139936673350912 [label="model.actor2lane_attention.attention_layers.0.dst_encoder.0.weight
 (128, 128)" fillcolor=lightblue]
	139936673350912 -> 139938312145408
	139938312145408 [label=AccumulateGrad]
	139938312143584 -> 139938312143344
	139938312143584 -> 139939054452928 [dir=none]
	139939054452928 [label="mat1
 (156865, 128)" fillcolor=orange]
	139938312143584 -> 139939054453824 [dir=none]
	139939054453824 [label="mat2
 (128, 128)" fillcolor=orange]
	139938312143584 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :  (156865, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139938312143776 -> 139938312143584
	139936673352448 [label="model.actor2lane_attention.attention_layers.0.edge_encoder.2.bias
 (128)" fillcolor=lightblue]
	139936673352448 -> 139938312143776
	139938312143776 [label=AccumulateGrad]
	139938312144016 -> 139938312143584
	139938312144016 -> 139939054454656 [dir=none]
	139939054454656 [label="result
 (156865, 128)" fillcolor=orange]
	139938312144016 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139938312145984 -> 139938312144016
	139938312145984 -> 139939054454592 [dir=none]
	139939054454592 [label="mat1
 (156865, 384)" fillcolor=orange]
	139938312145984 -> 139939054455616 [dir=none]
	139939054455616 [label="mat2
 (384, 128)" fillcolor=orange]
	139938312145984 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :  (156865, 384)
mat1_strides:       (384, 1)
mat2        : [saved tensor]
mat2_sizes  :     (384, 128)
mat2_strides:       (1, 384)"]
	139938312143200 -> 139938312145984
	139936673352128 [label="model.actor2lane_attention.attention_layers.0.edge_encoder.0.bias
 (128)" fillcolor=lightblue]
	139936673352128 -> 139938312143200
	139938312143200 [label=AccumulateGrad]
	139938312145168 -> 139938312145984
	139938312145168 [label="CatBackward
-------------------------
dim: 18446744073709551615"]
	139936692266176 -> 139938312145168
	139936692266176 -> 139939054456384 [dir=none]
	139939054456384 [label="indices[0]
 (156865)" fillcolor=orange]
	139936692266176 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:       (68, 128)"]
	139936692265312 -> 139936692266176
	139936692265312 -> 139939054455744 [dir=none]
	139939054455744 [label="result
 (68, 128)" fillcolor=orange]
	139936692265312 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936692265456 -> 139936692265312
	139936692265456 -> 139939054453440 [dir=none]
	139939054453440 [label="mat1
 (68, 128)" fillcolor=orange]
	139936692265456 -> 139939054455104 [dir=none]
	139939054455104 [label="mat2
 (128, 128)" fillcolor=orange]
	139936692265456 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (68, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139936692265552 -> 139936692265456
	139936673350336 [label="model.actor2lane_attention.attention_layers.0.src_encoder.0.bias
 (128)" fillcolor=lightblue]
	139936673350336 -> 139936692265552
	139936692265552 [label=AccumulateGrad]
	139936686547248 -> 139936692265456
	139936692265504 -> 139936692265456
	139936692265504 [label=TBackward]
	139936692265648 -> 139936692265504
	139936673350272 [label="model.actor2lane_attention.attention_layers.0.src_encoder.0.weight
 (128, 128)" fillcolor=lightblue]
	139936673350272 -> 139936692265648
	139936692265648 [label=AccumulateGrad]
	139936692268864 -> 139938312145168
	139936692268864 -> 139939054452992 [dir=none]
	139939054452992 [label="result
 (156865, 128)" fillcolor=orange]
	139936692268864 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936692267712 -> 139936692268864
	139936692267712 -> 139939054455296 [dir=none]
	139939054455296 [label="mat1
 (156865, 2)" fillcolor=orange]
	139936692267712 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (156865, 2)
mat1_strides:             ()
mat2        :           None
mat2_sizes  :       (2, 128)
mat2_strides:         (1, 2)"]
	139936692265936 -> 139936692267712
	139936673351552 [label="model.actor2lane_attention.attention_layers.0.edge_dist_encoder.0.bias
 (128)" fillcolor=lightblue]
	139936673351552 -> 139936692265936
	139936692265936 [label=AccumulateGrad]
	139936692265696 -> 139936692267712
	139936692265696 [label=TBackward]
	139936692265840 -> 139936692265696
	139936673351424 [label="model.actor2lane_attention.attention_layers.0.edge_dist_encoder.0.weight
 (128, 2)" fillcolor=lightblue]
	139936673351424 -> 139936692265840
	139936692265840 [label=AccumulateGrad]
	139936692265072 -> 139938312145168
	139936692265072 -> 139939054454464 [dir=none]
	139939054454464 [label="indices[0]
 (156865)" fillcolor=orange]
	139936692265072 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139938312143968 -> 139936692265072
	139938312144688 -> 139938312145984
	139938312144688 [label=TBackward]
	139936692265744 -> 139938312144688
	139936673352000 [label="model.actor2lane_attention.attention_layers.0.edge_encoder.0.weight
 (128, 384)" fillcolor=lightblue]
	139936673352000 -> 139936692265744
	139936692265744 [label=AccumulateGrad]
	139938312143824 -> 139938312143584
	139938312143824 [label=TBackward]
	139938312146608 -> 139938312143824
	139936673352256 [label="model.actor2lane_attention.attention_layers.0.edge_encoder.2.weight
 (128, 128)" fillcolor=lightblue]
	139936673352256 -> 139938312146608
	139938312146608 [label=AccumulateGrad]
	139938312143248 -> 139938312143008
	139936673353024 [label="model.actor2lane_attention.attention_layers.0.dst_feature_norm.weight
 (128)" fillcolor=lightblue]
	139936673353024 -> 139938312143248
	139938312143248 [label=AccumulateGrad]
	139938312143104 -> 139938312143008
	139936673352896 [label="model.actor2lane_attention.attention_layers.0.dst_feature_norm.bias
 (128)" fillcolor=lightblue]
	139936673352896 -> 139938312143104
	139938312143104 [label=AccumulateGrad]
	139938130439904 -> 139938130439856
	139938130439904 [label=TBackward]
	139938312143536 -> 139938130439904
	139936673352640 [label="model.actor2lane_attention.attention_layers.0.output_linear.weight
 (128, 128)" fillcolor=lightblue]
	139936673352640 -> 139938312143536
	139938312143536 [label=AccumulateGrad]
	139938130439712 -> 139938130439472
	139938130439376 -> 139938130439328
	139938130439376 [label=TBackward]
	139938130440144 -> 139938130439376
	139936673194432 [label="model.actor2lane_attention.attention_layers.1.dst_encoder.0.weight
 (128, 128)" fillcolor=lightblue]
	139936673194432 -> 139938130440144
	139938130440144 [label=AccumulateGrad]
	139938130438896 -> 139938130438704
	139938130438896 -> 139939054455360 [dir=none]
	139939054455360 [label="mat1
 (156865, 128)" fillcolor=orange]
	139938130438896 -> 139939054456064 [dir=none]
	139939054456064 [label="mat2
 (128, 128)" fillcolor=orange]
	139938130438896 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :  (156865, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139938130439040 -> 139938130438896
	139936673195968 [label="model.actor2lane_attention.attention_layers.1.edge_encoder.2.bias
 (128)" fillcolor=lightblue]
	139936673195968 -> 139938130439040
	139938130439040 [label=AccumulateGrad]
	139938130439280 -> 139938130438896
	139938130439280 -> 139939054453568 [dir=none]
	139939054453568 [label="result
 (156865, 128)" fillcolor=orange]
	139938130439280 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139938130439568 -> 139938130439280
	139938130439568 -> 139939054455168 [dir=none]
	139939054455168 [label="mat1
 (156865, 384)" fillcolor=orange]
	139938130439568 -> 139939054456576 [dir=none]
	139939054456576 [label="mat2
 (384, 128)" fillcolor=orange]
	139938130439568 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :  (156865, 384)
mat1_strides:       (384, 1)
mat2        : [saved tensor]
mat2_sizes  :     (384, 128)
mat2_strides:       (1, 384)"]
	139938312143056 -> 139938130439568
	139936673195648 [label="model.actor2lane_attention.attention_layers.1.edge_encoder.0.bias
 (128)" fillcolor=lightblue]
	139936673195648 -> 139938312143056
	139938312143056 [label=AccumulateGrad]
	139938312144736 -> 139938130439568
	139938312144736 [label="CatBackward
-------------------------
dim: 18446744073709551615"]
	139936692266128 -> 139938312144736
	139936692266128 -> 139939054453376 [dir=none]
	139939054453376 [label="indices[0]
 (156865)" fillcolor=orange]
	139936692266128 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:       (68, 128)"]
	139936692266272 -> 139936692266128
	139936692266272 -> 139939054454912 [dir=none]
	139939054454912 [label="result
 (68, 128)" fillcolor=orange]
	139936692266272 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936692266416 -> 139936692266272
	139936692266416 -> 139939054456320 [dir=none]
	139939054456320 [label="mat1
 (68, 128)" fillcolor=orange]
	139936692266416 -> 139939054454016 [dir=none]
	139939054454016 [label="mat2
 (128, 128)" fillcolor=orange]
	139936692266416 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (68, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139936692266512 -> 139936692266416
	139936673353408 [label="model.actor2lane_attention.attention_layers.1.src_encoder.0.bias
 (128)" fillcolor=lightblue]
	139936673353408 -> 139936692266512
	139936692266512 [label=AccumulateGrad]
	139936686547248 -> 139936692266416
	139936692266464 -> 139936692266416
	139936692266464 [label=TBackward]
	139936692266656 -> 139936692266464
	139936673353472 [label="model.actor2lane_attention.attention_layers.1.src_encoder.0.weight
 (128, 128)" fillcolor=lightblue]
	139936673353472 -> 139936692266656
	139936692266656 [label=AccumulateGrad]
	139936692265360 -> 139938312144736
	139936692265360 -> 139939054453952 [dir=none]
	139939054453952 [label="result
 (156865, 128)" fillcolor=orange]
	139936692265360 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936692266080 -> 139936692265360
	139936692266080 -> 139939054453312 [dir=none]
	139939054453312 [label="mat1
 (156865, 2)" fillcolor=orange]
	139936692266080 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (156865, 2)
mat1_strides:             ()
mat2        :           None
mat2_sizes  :       (2, 128)
mat2_strides:         (1, 2)"]
	139936692266896 -> 139936692266080
	139936673195072 [label="model.actor2lane_attention.attention_layers.1.edge_dist_encoder.0.bias
 (128)" fillcolor=lightblue]
	139936673195072 -> 139936692266896
	139936692266896 [label=AccumulateGrad]
	139936692266704 -> 139936692266080
	139936692266704 [label=TBackward]
	139936692266848 -> 139936692266704
	139936673194944 [label="model.actor2lane_attention.attention_layers.1.edge_dist_encoder.0.weight
 (128, 2)" fillcolor=lightblue]
	139936673194944 -> 139936692266848
	139936692266848 [label=AccumulateGrad]
	139936692265216 -> 139938312144736
	139936692265216 -> 139936676974272 [dir=none]
	139936676974272 [label="indices[0]
 (156865)" fillcolor=orange]
	139936692265216 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139938130439184 -> 139936692265216
	139938312143488 -> 139938130439568
	139938312143488 [label=TBackward]
	139936692266800 -> 139938312143488
	139936673195520 [label="model.actor2lane_attention.attention_layers.1.edge_encoder.0.weight
 (128, 384)" fillcolor=lightblue]
	139936673195520 -> 139936692266800
	139936692266800 [label=AccumulateGrad]
	139938130439136 -> 139938130438896
	139938130439136 [label=TBackward]
	139938312146128 -> 139938130439136
	139936673195776 [label="model.actor2lane_attention.attention_layers.1.edge_encoder.2.weight
 (128, 128)" fillcolor=lightblue]
	139936673195776 -> 139938312146128
	139938312146128 [label=AccumulateGrad]
	139938130438608 -> 139938130438320
	139936673196544 [label="model.actor2lane_attention.attention_layers.1.dst_feature_norm.weight
 (128)" fillcolor=lightblue]
	139936673196544 -> 139938130438608
	139938130438608 [label=AccumulateGrad]
	139938130438560 -> 139938130438320
	139936673196416 [label="model.actor2lane_attention.attention_layers.1.dst_feature_norm.bias
 (128)" fillcolor=lightblue]
	139936673196416 -> 139938130438560
	139938130438560 [label=AccumulateGrad]
	139938130438032 -> 139938130437984
	139938130438032 [label=TBackward]
	139938130438848 -> 139938130438032
	139936673196160 [label="model.actor2lane_attention.attention_layers.1.output_linear.weight
 (128, 128)" fillcolor=lightblue]
	139936673196160 -> 139938130438848
	139938130438848 [label=AccumulateGrad]
	139938130437840 -> 139938130437552
	139938130437264 -> 139938130437168
	139938130437264 [label=TBackward]
	139938130438272 -> 139938130437264
	139936673197632 [label="model.actor2lane_attention.attention_layers.2.dst_encoder.0.weight
 (128, 128)" fillcolor=lightblue]
	139936673197632 -> 139938130438272
	139938130438272 [label=AccumulateGrad]
	139938130436544 -> 139938130436304
	139938130436544 -> 139936676971328 [dir=none]
	139936676971328 [label="mat1
 (156865, 128)" fillcolor=orange]
	139938130436544 -> 139936676973568 [dir=none]
	139936676973568 [label="mat2
 (128, 128)" fillcolor=orange]
	139938130436544 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :  (156865, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139938130436688 -> 139938130436544
	139936673567872 [label="model.actor2lane_attention.attention_layers.2.edge_encoder.2.bias
 (128)" fillcolor=lightblue]
	139936673567872 -> 139938130436688
	139938130436688 [label=AccumulateGrad]
	139938130437120 -> 139938130436544
	139938130437120 -> 139936676974528 [dir=none]
	139936676974528 [label="result
 (156865, 128)" fillcolor=orange]
	139938130437120 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139938130439616 -> 139938130437120
	139938130439616 -> 139936676973696 [dir=none]
	139936676973696 [label="mat1
 (156865, 384)" fillcolor=orange]
	139938130439616 -> 139936676972736 [dir=none]
	139936676972736 [label="mat2
 (384, 128)" fillcolor=orange]
	139938130439616 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :  (156865, 384)
mat1_strides:       (384, 1)
mat2        : [saved tensor]
mat2_sizes  :     (384, 128)
mat2_strides:       (1, 384)"]
	139938130438416 -> 139938130439616
	139936673567552 [label="model.actor2lane_attention.attention_layers.2.edge_encoder.0.bias
 (128)" fillcolor=lightblue]
	139936673567552 -> 139938130438416
	139938130438416 [label=AccumulateGrad]
	139938130437600 -> 139938130439616
	139938130437600 [label="CatBackward
-------------------------
dim: 18446744073709551615"]
	139936692267040 -> 139938130437600
	139936692267040 -> 139936676973440 [dir=none]
	139936676973440 [label="indices[0]
 (156865)" fillcolor=orange]
	139936692267040 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:       (68, 128)"]
	139936692267184 -> 139936692267040
	139936692267184 -> 139936676972672 [dir=none]
	139936676972672 [label="result
 (68, 128)" fillcolor=orange]
	139936692267184 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936692267280 -> 139936692267184
	139936692267280 -> 139936676972864 [dir=none]
	139936676972864 [label="mat1
 (68, 128)" fillcolor=orange]
	139936692267280 -> 139936676971776 [dir=none]
	139936676971776 [label="mat2
 (128, 128)" fillcolor=orange]
	139936692267280 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (68, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139936692267424 -> 139936692267280
	139936673196928 [label="model.actor2lane_attention.attention_layers.2.src_encoder.0.bias
 (128)" fillcolor=lightblue]
	139936673196928 -> 139936692267424
	139936692267424 [label=AccumulateGrad]
	139936686547248 -> 139936692267280
	139936692267376 -> 139936692267280
	139936692267376 [label=TBackward]
	139936692267472 -> 139936692267376
	139936673196992 [label="model.actor2lane_attention.attention_layers.2.src_encoder.0.weight
 (128, 128)" fillcolor=lightblue]
	139936673196992 -> 139936692267472
	139936692267472 [label=AccumulateGrad]
	139936692266320 -> 139938130437600
	139936692266320 -> 139936676971392 [dir=none]
	139936676971392 [label="result
 (156865, 128)" fillcolor=orange]
	139936692266320 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936692266992 -> 139936692266320
	139936692266992 -> 139936676970624 [dir=none]
	139936676970624 [label="mat1
 (156865, 2)" fillcolor=orange]
	139936692266992 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (156865, 2)
mat1_strides:             ()
mat2        :           None
mat2_sizes  :       (2, 128)
mat2_strides:         (1, 2)"]
	139936692267664 -> 139936692266992
	139936673566976 [label="model.actor2lane_attention.attention_layers.2.edge_dist_encoder.0.bias
 (128)" fillcolor=lightblue]
	139936673566976 -> 139936692267664
	139936692267664 [label=AccumulateGrad]
	139936692267520 -> 139936692266992
	139936692267520 [label=TBackward]
	139936692267616 -> 139936692267520
	139936673566848 [label="model.actor2lane_attention.attention_layers.2.edge_dist_encoder.0.weight
 (128, 2)" fillcolor=lightblue]
	139936673566848 -> 139936692267616
	139936692267616 [label=AccumulateGrad]
	139936692265120 -> 139938130437600
	139936692265120 -> 139936676971968 [dir=none]
	139936676971968 [label="indices[0]
 (156865)" fillcolor=orange]
	139936692265120 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139938130436976 -> 139936692265120
	139936692266032 -> 139938130439616
	139936692266032 [label=TBackward]
	139936692267568 -> 139936692266032
	139936673567424 [label="model.actor2lane_attention.attention_layers.2.edge_encoder.0.weight
 (128, 384)" fillcolor=lightblue]
	139936673567424 -> 139936692267568
	139936692267568 [label=AccumulateGrad]
	139938130436832 -> 139938130436544
	139938130436832 [label=TBackward]
	139938130438752 -> 139938130436832
	139936673567680 [label="model.actor2lane_attention.attention_layers.2.edge_encoder.2.weight
 (128, 128)" fillcolor=lightblue]
	139936673567680 -> 139938130438752
	139938130438752 [label=AccumulateGrad]
	139938130440000 -> 139938130439760
	139936673568448 [label="model.actor2lane_attention.attention_layers.2.dst_feature_norm.weight
 (128)" fillcolor=lightblue]
	139936673568448 -> 139938130440000
	139938130440000 [label=AccumulateGrad]
	139938130439952 -> 139938130439760
	139936673568320 [label="model.actor2lane_attention.attention_layers.2.dst_feature_norm.bias
 (128)" fillcolor=lightblue]
	139936673568320 -> 139938130439952
	139938130439952 [label=AccumulateGrad]
	139938130439088 -> 139938130438944
	139938130439088 [label=TBackward]
	139938130436448 -> 139938130439088
	139936673568064 [label="model.actor2lane_attention.attention_layers.2.output_linear.weight
 (128, 128)" fillcolor=lightblue]
	139936673568064 -> 139938130436448
	139938130436448 [label=AccumulateGrad]
	139938130438800 -> 139938130438224
	139938130437936 -> 139938130437792
	139938130437936 [label=TBackward]
	139938130439664 -> 139938130437936
	139936673569536 [label="model.actor2lane_attention.attention_layers.3.dst_encoder.0.weight
 (128, 128)" fillcolor=lightblue]
	139936673569536 -> 139938130439664
	139938130439664 [label=AccumulateGrad]
	139938130437216 -> 139938130436928
	139938130437216 -> 139936676972480 [dir=none]
	139936676972480 [label="mat1
 (156865, 128)" fillcolor=orange]
	139938130437216 -> 139936676971840 [dir=none]
	139936676971840 [label="mat2
 (128, 128)" fillcolor=orange]
	139938130437216 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :  (156865, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139938130437360 -> 139938130437216
	139936673411392 [label="model.actor2lane_attention.attention_layers.3.edge_encoder.2.bias
 (128)" fillcolor=lightblue]
	139936673411392 -> 139938130437360
	139938130437360 [label=AccumulateGrad]
	139938130437648 -> 139938130437216
	139938130437648 -> 139936676971136 [dir=none]
	139936676971136 [label="result
 (156865, 128)" fillcolor=orange]
	139938130437648 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139938130437744 -> 139938130437648
	139938130437744 -> 139936676971584 [dir=none]
	139936676971584 [label="mat1
 (156865, 384)" fillcolor=orange]
	139938130437744 -> 139936676974464 [dir=none]
	139936676974464 [label="mat2
 (384, 128)" fillcolor=orange]
	139938130437744 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :  (156865, 384)
mat1_strides:       (384, 1)
mat2        : [saved tensor]
mat2_sizes  :     (384, 128)
mat2_strides:       (1, 384)"]
	139938130439808 -> 139938130437744
	139936673411136 [label="model.actor2lane_attention.attention_layers.3.edge_encoder.0.bias
 (128)" fillcolor=lightblue]
	139936673411136 -> 139938130439808
	139938130439808 [label=AccumulateGrad]
	139938130438368 -> 139938130437744
	139938130438368 [label="CatBackward
-------------------------
dim: 18446744073709551615"]
	139936692267856 -> 139938130438368
	139936692267856 -> 139936676972992 [dir=none]
	139936676972992 [label="indices[0]
 (156865)" fillcolor=orange]
	139936692267856 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:       (68, 128)"]
	139936692268000 -> 139936692267856
	139936692268000 -> 139936686273920 [dir=none]
	139936686273920 [label="result
 (68, 128)" fillcolor=orange]
	139936692268000 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936692268192 -> 139936692268000
	139936692268192 -> 139936686274624 [dir=none]
	139936686274624 [label="mat1
 (68, 128)" fillcolor=orange]
	139936692268192 -> 139936686274752 [dir=none]
	139936686274752 [label="mat2
 (128, 128)" fillcolor=orange]
	139936692268192 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (68, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139936692268336 -> 139936692268192
	139936673568832 [label="model.actor2lane_attention.attention_layers.3.src_encoder.0.bias
 (128)" fillcolor=lightblue]
	139936673568832 -> 139936692268336
	139936692268336 [label=AccumulateGrad]
	139936686547248 -> 139936692268192
	139936692268240 -> 139936692268192
	139936692268240 [label=TBackward]
	139936692268384 -> 139936692268240
	139936673568896 [label="model.actor2lane_attention.attention_layers.3.src_encoder.0.weight
 (128, 128)" fillcolor=lightblue]
	139936673568896 -> 139936692268384
	139936692268384 [label=AccumulateGrad]
	139936692267232 -> 139938130438368
	139936692267232 -> 139936686275904 [dir=none]
	139936686275904 [label="result
 (156865, 128)" fillcolor=orange]
	139936692267232 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936692267808 -> 139936692267232
	139936692267808 -> 139936686274496 [dir=none]
	139936686274496 [label="mat1
 (156865, 2)" fillcolor=orange]
	139936692267808 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (156865, 2)
mat1_strides:             ()
mat2        :           None
mat2_sizes  :       (2, 128)
mat2_strides:         (1, 2)"]
	139936692268624 -> 139936692267808
	139936673570176 [label="model.actor2lane_attention.attention_layers.3.edge_dist_encoder.0.bias
 (128)" fillcolor=lightblue]
	139936673570176 -> 139936692268624
	139936692268624 [label=AccumulateGrad]
	139936692268432 -> 139936692267808
	139936692268432 [label=TBackward]
	139936692268576 -> 139936692268432
	139936673570048 [label="model.actor2lane_attention.attention_layers.3.edge_dist_encoder.0.weight
 (128, 2)" fillcolor=lightblue]
	139936673570048 -> 139936692268576
	139936692268576 [label=AccumulateGrad]
	139936692265264 -> 139938130438368
	139936692265264 -> 139936686276224 [dir=none]
	139936686276224 [label="indices[0]
 (156865)" fillcolor=orange]
	139936692265264 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139938130437504 -> 139936692265264
	139936692266944 -> 139938130437744
	139936692266944 [label=TBackward]
	139936692268528 -> 139936692266944
	139936673570624 [label="model.actor2lane_attention.attention_layers.3.edge_encoder.0.weight
 (128, 384)" fillcolor=lightblue]
	139936673570624 -> 139936692268528
	139936692268528 [label=AccumulateGrad]
	139938130437408 -> 139938130437216
	139938130437408 [label=TBackward]
	139938130436400 -> 139938130437408
	139936673411200 [label="model.actor2lane_attention.attention_layers.3.edge_encoder.2.weight
 (128, 128)" fillcolor=lightblue]
	139936673411200 -> 139938130436400
	139938130436400 [label=AccumulateGrad]
	139938130436880 -> 139938130436640
	139936673411968 [label="model.actor2lane_attention.attention_layers.3.dst_feature_norm.weight
 (128)" fillcolor=lightblue]
	139936673411968 -> 139938130436880
	139938130436880 [label=AccumulateGrad]
	139938130436784 -> 139938130436640
	139936673411840 [label="model.actor2lane_attention.attention_layers.3.dst_feature_norm.bias
 (128)" fillcolor=lightblue]
	139936673411840 -> 139938130436784
	139938130436784 [label=AccumulateGrad]
	139938130436208 -> 139939050572672
	139938130436208 [label=TBackward]
	139938130437072 -> 139938130436208
	139936673411584 [label="model.actor2lane_attention.attention_layers.3.output_linear.weight
 (128, 128)" fillcolor=lightblue]
	139936673411584 -> 139938130437072
	139938130437072 [label=AccumulateGrad]
	139939050572288 -> 139939050570944
	139939050571328 -> 139939050573248
	139939050571328 [label=TBackward]
	139939050571712 -> 139939050571328
	139936673412672 [label="model.lane2actor_attention.attention_layers.0.src_encoder.0.weight
 (128, 128)" fillcolor=lightblue]
	139936673412672 -> 139939050571712
	139939050571712 [label=AccumulateGrad]
	139939050569792 -> 139939050569984
	139939050569792 -> 139938016744256 [dir=none]
	139938016744256 [label="result
 (156865, 128)" fillcolor=orange]
	139939050569792 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139939050570368 -> 139939050569792
	139939050570368 -> 139936686276480 [dir=none]
	139936686276480 [label="mat1
 (156865, 2)" fillcolor=orange]
	139939050570368 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (156865, 2)
mat1_strides:             ()
mat2        :           None
mat2_sizes  :       (2, 128)
mat2_strides:         (1, 2)"]
	139939050571904 -> 139939050570368
	139936673414144 [label="model.lane2actor_attention.attention_layers.0.edge_dist_encoder.0.bias
 (128)" fillcolor=lightblue]
	139936673414144 -> 139939050571904
	139939050571904 [label=AccumulateGrad]
	139938130438656 -> 139939050570368
	139938130438656 [label=TBackward]
	139938130437024 -> 139938130438656
	139936673414016 [label="model.lane2actor_attention.attention_layers.0.edge_dist_encoder.0.weight
 (128, 2)" fillcolor=lightblue]
	139936673414016 -> 139938130437024
	139938130437024 [label=AccumulateGrad]
	139939050572864 -> 139939050569984
	139939050572864 -> 139936686274368 [dir=none]
	139936686274368 [label="indices[0]
 (156865)" fillcolor=orange]
	139939050572864 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:       (68, 128)"]
	139939050569840 -> 139939050572864
	139939050571472 -> 139939050570176
	139939050571472 [label=TBackward]
	139939050573056 -> 139939050571472
	139936673414592 [label="model.lane2actor_attention.attention_layers.0.edge_encoder.0.weight
 (128, 384)" fillcolor=lightblue]
	139936673414592 -> 139939050573056
	139939050573056 [label=AccumulateGrad]
	139939050570272 -> 139939050572096
	139939050570272 [label=TBackward]
	139939050571520 -> 139939050570272
	139936673414848 [label="model.lane2actor_attention.attention_layers.0.edge_encoder.2.weight
 (128, 128)" fillcolor=lightblue]
	139936673414848 -> 139939050571520
	139939050571520 [label=AccumulateGrad]
	139936686550560 -> 139936686550272
	139936675086848 [label="model.lane2actor_attention.attention_layers.0.dst_feature_norm.weight
 (128)" fillcolor=lightblue]
	139936675086848 -> 139936686550560
	139936686550560 [label=AccumulateGrad]
	139936686548688 -> 139936686550272
	139936675086720 [label="model.lane2actor_attention.attention_layers.0.dst_feature_norm.bias
 (128)" fillcolor=lightblue]
	139936675086720 -> 139936686548688
	139936686548688 [label=AccumulateGrad]
	139936686548352 -> 139936686547968
	139936686548352 [label=TBackward]
	139936686548208 -> 139936686548352
	139936675086464 [label="model.lane2actor_attention.attention_layers.0.output_linear.weight
 (128, 128)" fillcolor=lightblue]
	139936675086464 -> 139936686548208
	139936686548208 [label=AccumulateGrad]
	139936686547248 -> 139936686548160
	139936693189168 -> 139936693190320
	139936693189168 [label=TBackward]
	139936686549120 -> 139936693189168
	139936675087936 [label="model.lane2actor_attention.attention_layers.1.dst_encoder.0.weight
 (128, 128)" fillcolor=lightblue]
	139936675087936 -> 139936686549120
	139936686549120 [label=AccumulateGrad]
	139936693187488 -> 139936693188928
	139936693187488 -> 139936686275456 [dir=none]
	139936686275456 [label="mat1
 (156865, 128)" fillcolor=orange]
	139936693187488 -> 139936686273216 [dir=none]
	139936686273216 [label="mat2
 (128, 128)" fillcolor=orange]
	139936693187488 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :  (156865, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139936693189360 -> 139936693187488
	139936675089472 [label="model.lane2actor_attention.attention_layers.1.edge_encoder.2.bias
 (128)" fillcolor=lightblue]
	139936675089472 -> 139936693189360
	139936693189360 [label=AccumulateGrad]
	139936693187824 -> 139936693187488
	139936693187824 -> 139936686275520 [dir=none]
	139936686275520 [label="result
 (156865, 128)" fillcolor=orange]
	139936693187824 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936686550080 -> 139936693187824
	139936686550080 -> 139936686274432 [dir=none]
	139936686274432 [label="mat1
 (156865, 384)" fillcolor=orange]
	139936686550080 -> 139936686275008 [dir=none]
	139936686275008 [label="mat2
 (384, 128)" fillcolor=orange]
	139936686550080 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :  (156865, 384)
mat1_strides:       (384, 1)
mat2        : [saved tensor]
mat2_sizes  :     (384, 128)
mat2_strides:       (1, 384)"]
	139939050569888 -> 139936686550080
	139936675089152 [label="model.lane2actor_attention.attention_layers.1.edge_encoder.0.bias
 (128)" fillcolor=lightblue]
	139936675089152 -> 139939050569888
	139939050569888 [label=AccumulateGrad]
	139939050573008 -> 139936686550080
	139939050573008 [label="CatBackward
-------------------------
dim: 18446744073709551615"]
	139938130436496 -> 139939050573008
	139938130436496 -> 139936686272768 [dir=none]
	139936686272768 [label="indices[0]
 (156865)" fillcolor=orange]
	139938130436496 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139936692266224 -> 139938130436496
	139936692266224 -> 139936686272960 [dir=none]
	139936686272960 [label="result
 (9921, 128)" fillcolor=orange]
	139936692266224 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936692268720 -> 139936692266224
	139936692268720 -> 139936686275648 [dir=none]
	139936686275648 [label="mat1
 (9921, 128)" fillcolor=orange]
	139936692268720 -> 139936686273664 [dir=none]
	139936686273664 [label="mat2
 (128, 128)" fillcolor=orange]
	139936692268720 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (9921, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139936692268912 -> 139936692268720
	139936675087232 [label="model.lane2actor_attention.attention_layers.1.src_encoder.0.bias
 (128)" fillcolor=lightblue]
	139936675087232 -> 139936692268912
	139936692268912 [label=AccumulateGrad]
	139939050573440 -> 139936692268720
	139936692268672 -> 139936692268720
	139936692268672 [label=TBackward]
	139936692268960 -> 139936692268672
	139936675087296 [label="model.lane2actor_attention.attention_layers.1.src_encoder.0.weight
 (128, 128)" fillcolor=lightblue]
	139936675087296 -> 139936692268960
	139936692268960 [label=AccumulateGrad]
	139938130436160 -> 139939050573008
	139938130436160 -> 139938013518784 [dir=none]
	139938013518784 [label="result
 (156865, 128)" fillcolor=orange]
	139938130436160 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936692267760 -> 139938130436160
	139936692267760 -> 139938013519232 [dir=none]
	139938013519232 [label="mat1
 (156865, 2)" fillcolor=orange]
	139936692267760 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (156865, 2)
mat1_strides:             ()
mat2        :           None
mat2_sizes  :       (2, 128)
mat2_strides:         (1, 2)"]
	139936692269008 -> 139936692267760
	139936675088576 [label="model.lane2actor_attention.attention_layers.1.edge_dist_encoder.0.bias
 (128)" fillcolor=lightblue]
	139936675088576 -> 139936692269008
	139936692269008 [label=AccumulateGrad]
	139936692267088 -> 139936692267760
	139936692267088 [label=TBackward]
	139936693481584 -> 139936692267088
	139936675088448 [label="model.lane2actor_attention.attention_layers.1.edge_dist_encoder.0.weight
 (128, 2)" fillcolor=lightblue]
	139936675088448 -> 139936693481584
	139936693481584 [label=AccumulateGrad]
	139936692267952 -> 139939050573008
	139936692267952 -> 139938013518720 [dir=none]
	139938013518720 [label="indices[0]
 (156865)" fillcolor=orange]
	139936692267952 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:       (68, 128)"]
	139936693189600 -> 139936692267952
	139939050573488 -> 139936686550080
	139939050573488 [label=TBackward]
	139936692268768 -> 139939050573488
	139936675089024 [label="model.lane2actor_attention.attention_layers.1.edge_encoder.0.weight
 (128, 384)" fillcolor=lightblue]
	139936675089024 -> 139936692268768
	139936692268768 [label=AccumulateGrad]
	139936686548832 -> 139936693187488
	139936686548832 [label=TBackward]
	139936692268048 -> 139936686548832
	139936675089280 [label="model.lane2actor_attention.attention_layers.1.edge_encoder.2.weight
 (128, 128)" fillcolor=lightblue]
	139936675089280 -> 139936692268048
	139936692268048 [label=AccumulateGrad]
	139936693189312 -> 139936693190464
	139936675090048 [label="model.lane2actor_attention.attention_layers.1.dst_feature_norm.weight
 (128)" fillcolor=lightblue]
	139936675090048 -> 139936693189312
	139936693189312 [label=AccumulateGrad]
	139936693187008 -> 139936693190464
	139936675089920 [label="model.lane2actor_attention.attention_layers.1.dst_feature_norm.bias
 (128)" fillcolor=lightblue]
	139936675089920 -> 139936693187008
	139936693187008 [label=AccumulateGrad]
	139936693189984 -> 139936693190080
	139936693189984 [label=TBackward]
	139936693186768 -> 139936693189984
	139936675089664 [label="model.lane2actor_attention.attention_layers.1.output_linear.weight
 (128, 128)" fillcolor=lightblue]
	139936675089664 -> 139936693186768
	139936693186768 [label=AccumulateGrad]
	139936693189696 -> 139936693189456
	139936693189024 -> 139936693188544
	139936693189024 [label=TBackward]
	139939050573344 -> 139936693189024
	139936675459840 [label="model.lane2actor_attention.attention_layers.2.dst_encoder.0.weight
 (128, 128)" fillcolor=lightblue]
	139936675459840 -> 139939050573344
	139939050573344 [label=AccumulateGrad]
	139936693187728 -> 139936693187632
	139936693187728 -> 139938013518016 [dir=none]
	139938013518016 [label="mat1
 (156865, 128)" fillcolor=orange]
	139936693187728 -> 139938013516224 [dir=none]
	139938013516224 [label="mat2
 (128, 128)" fillcolor=orange]
	139936693187728 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :  (156865, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139938130436736 -> 139936693187728
	139936675461376 [label="model.lane2actor_attention.attention_layers.2.edge_encoder.2.bias
 (128)" fillcolor=lightblue]
	139936675461376 -> 139938130436736
	139938130436736 [label=AccumulateGrad]
	139936693188688 -> 139936693187728
	139936693188688 -> 139938013519488 [dir=none]
	139938013519488 [label="result
 (156865, 128)" fillcolor=orange]
	139936693188688 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936693190560 -> 139936693188688
	139936693190560 -> 139938013518400 [dir=none]
	139938013518400 [label="mat1
 (156865, 384)" fillcolor=orange]
	139936693190560 -> 139938013519808 [dir=none]
	139938013519808 [label="mat2
 (384, 128)" fillcolor=orange]
	139936693190560 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :  (156865, 384)
mat1_strides:       (384, 1)
mat2        : [saved tensor]
mat2_sizes  :     (384, 128)
mat2_strides:       (1, 384)"]
	139936693187968 -> 139936693190560
	139936675461056 [label="model.lane2actor_attention.attention_layers.2.edge_encoder.0.bias
 (128)" fillcolor=lightblue]
	139936675461056 -> 139936693187968
	139936693187968 [label=AccumulateGrad]
	139936693187152 -> 139936693190560
	139936693187152 [label="CatBackward
-------------------------
dim: 18446744073709551615"]
	139936686550608 -> 139936693187152
	139936686550608 -> 139938013519552 [dir=none]
	139938013519552 [label="indices[0]
 (156865)" fillcolor=orange]
	139936686550608 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139936693482160 -> 139936686550608
	139936693482160 -> 139938013518336 [dir=none]
	139938013518336 [label="result
 (9921, 128)" fillcolor=orange]
	139936693482160 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936693482352 -> 139936693482160
	139936693482352 -> 139938013516736 [dir=none]
	139938013516736 [label="mat1
 (9921, 128)" fillcolor=orange]
	139936693482352 -> 139938013518656 [dir=none]
	139938013518656 [label="mat2
 (128, 128)" fillcolor=orange]
	139936693482352 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (9921, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139936693482544 -> 139936693482352
	139936675459136 [label="model.lane2actor_attention.attention_layers.2.src_encoder.0.bias
 (128)" fillcolor=lightblue]
	139936675459136 -> 139936693482544
	139936693482544 [label=AccumulateGrad]
	139939050573440 -> 139936693482352
	139936693482496 -> 139936693482352
	139936693482496 [label=TBackward]
	139936693482592 -> 139936693482496
	139936675459200 [label="model.lane2actor_attention.attention_layers.2.src_encoder.0.weight
 (128, 128)" fillcolor=lightblue]
	139936675459200 -> 139936693482592
	139936693482592 [label=AccumulateGrad]
	139936693481872 -> 139936693187152
	139936693481872 -> 139938013515840 [dir=none]
	139938013515840 [label="result
 (156865, 128)" fillcolor=orange]
	139936693481872 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936693481824 -> 139936693481872
	139936693481824 -> 139938013517312 [dir=none]
	139938013517312 [label="mat1
 (156865, 2)" fillcolor=orange]
	139936693481824 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (156865, 2)
mat1_strides:             ()
mat2        :           None
mat2_sizes  :       (2, 128)
mat2_strides:         (1, 2)"]
	139936693483840 -> 139936693481824
	139936675460480 [label="model.lane2actor_attention.attention_layers.2.edge_dist_encoder.0.bias
 (128)" fillcolor=lightblue]
	139936675460480 -> 139936693483840
	139936693483840 [label=AccumulateGrad]
	139936693483024 -> 139936693481824
	139936693483024 [label=TBackward]
	139936693483264 -> 139936693483024
	139936675460352 [label="model.lane2actor_attention.attention_layers.2.edge_dist_encoder.0.weight
 (128, 2)" fillcolor=lightblue]
	139936675460352 -> 139936693483264
	139936693483264 [label=AccumulateGrad]
	139936693481632 -> 139936693187152
	139936693481632 -> 139939054088704 [dir=none]
	139939054088704 [label="indices[0]
 (156865)" fillcolor=orange]
	139936693481632 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:       (68, 128)"]
	139936693188352 -> 139936693481632
	139936693189120 -> 139936693190560
	139936693189120 [label=TBackward]
	139936693483072 -> 139936693189120
	139936675460928 [label="model.lane2actor_attention.attention_layers.2.edge_encoder.0.weight
 (128, 384)" fillcolor=lightblue]
	139936675460928 -> 139936693483072
	139936693483072 [label=AccumulateGrad]
	139936693188448 -> 139936693187728
	139936693188448 [label=TBackward]
	139936686549696 -> 139936693188448
	139936675461184 [label="model.lane2actor_attention.attention_layers.2.edge_encoder.2.weight
 (128, 128)" fillcolor=lightblue]
	139936675461184 -> 139936686549696
	139936686549696 [label=AccumulateGrad]
	139936693187056 -> 139936677106112
	139936675461952 [label="model.lane2actor_attention.attention_layers.2.dst_feature_norm.weight
 (128)" fillcolor=lightblue]
	139936675461952 -> 139936693187056
	139936693187056 [label=AccumulateGrad]
	139936693186912 -> 139936677106112
	139936675461824 [label="model.lane2actor_attention.attention_layers.2.dst_feature_norm.bias
 (128)" fillcolor=lightblue]
	139936675461824 -> 139936693186912
	139936693186912 [label=AccumulateGrad]
	139936677108128 -> 139936677108272
	139936677108128 [label=TBackward]
	139936692362784 -> 139936677108128
	139936675461568 [label="model.lane2actor_attention.attention_layers.2.output_linear.weight
 (128, 128)" fillcolor=lightblue]
	139936675461568 -> 139936692362784
	139936692362784 [label=AccumulateGrad]
	139936677107696 -> 139936677107360
	139936677106496 -> 139936677109424
	139936677106496 [label=TBackward]
	139936677106880 -> 139936677106496
	139936675463040 [label="model.lane2actor_attention.attention_layers.3.dst_encoder.0.weight
 (128, 128)" fillcolor=lightblue]
	139936675463040 -> 139936677106880
	139936677106880 [label=AccumulateGrad]
	139936677108560 -> 139936677108368
	139936677108560 -> 139939054089280 [dir=none]
	139939054089280 [label="mat1
 (156865, 128)" fillcolor=orange]
	139936677108560 -> 139939054088512 [dir=none]
	139939054088512 [label="mat2
 (128, 128)" fillcolor=orange]
	139936677108560 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :  (156865, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139936677108752 -> 139936677108560
	139936675259840 [label="model.lane2actor_attention.attention_layers.3.edge_encoder.2.bias
 (128)" fillcolor=lightblue]
	139936675259840 -> 139936677108752
	139936677108752 [label=AccumulateGrad]
	139936677109616 -> 139936677108560
	139936677109616 -> 139937981443776 [dir=none]
	139937981443776 [label="result
 (156865, 128)" fillcolor=orange]
	139936677109616 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936677107072 -> 139936677109616
	139936677107072 -> 139938013517504 [dir=none]
	139938013517504 [label="mat1
 (156865, 384)" fillcolor=orange]
	139936677107072 -> 139938013516416 [dir=none]
	139938013516416 [label="mat2
 (384, 128)" fillcolor=orange]
	139936677107072 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :  (156865, 384)
mat1_strides:       (384, 1)
mat2        : [saved tensor]
mat2_sizes  :     (384, 128)
mat2_strides:       (1, 384)"]
	139936693187536 -> 139936677107072
	139936675259520 [label="model.lane2actor_attention.attention_layers.3.edge_encoder.0.bias
 (128)" fillcolor=lightblue]
	139936675259520 -> 139936693187536
	139936693187536 [label=AccumulateGrad]
	139936693188112 -> 139936677107072
	139936693188112 [label="CatBackward
-------------------------
dim: 18446744073709551615"]
	139936693484416 -> 139936693188112
	139936693484416 -> 139939054089088 [dir=none]
	139939054089088 [label="indices[0]
 (156865)" fillcolor=orange]
	139936693484416 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:     (9921, 128)"]
	139936693484752 -> 139936693484416
	139936693484752 -> 139939054091008 [dir=none]
	139939054091008 [label="result
 (9921, 128)" fillcolor=orange]
	139936693484752 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936693484848 -> 139936693484752
	139936693484848 -> 139939054090368 [dir=none]
	139939054090368 [label="mat1
 (9921, 128)" fillcolor=orange]
	139936693484848 -> 139939054091200 [dir=none]
	139939054091200 [label="mat2
 (128, 128)" fillcolor=orange]
	139936693484848 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (9921, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139936693485088 -> 139936693484848
	139936675462336 [label="model.lane2actor_attention.attention_layers.3.src_encoder.0.bias
 (128)" fillcolor=lightblue]
	139936675462336 -> 139936693485088
	139936693485088 [label=AccumulateGrad]
	139939050573440 -> 139936693484848
	139936693484944 -> 139936693484848
	139936693484944 [label=TBackward]
	139936693485184 -> 139936693484944
	139936675462400 [label="model.lane2actor_attention.attention_layers.3.src_encoder.0.weight
 (128, 128)" fillcolor=lightblue]
	139936675462400 -> 139936693485184
	139936693485184 [label=AccumulateGrad]
	139936693482304 -> 139936693188112
	139936693482304 -> 139938013517568 [dir=none]
	139938013517568 [label="result
 (156865, 128)" fillcolor=orange]
	139936693482304 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936693484272 -> 139936693482304
	139936693484272 -> 139938013517824 [dir=none]
	139938013517824 [label="mat1
 (156865, 2)" fillcolor=orange]
	139936693484272 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :    (156865, 2)
mat1_strides:             ()
mat2        :           None
mat2_sizes  :       (2, 128)
mat2_strides:         (1, 2)"]
	139936693485520 -> 139936693484272
	139936675258944 [label="model.lane2actor_attention.attention_layers.3.edge_dist_encoder.0.bias
 (128)" fillcolor=lightblue]
	139936675258944 -> 139936693485520
	139936693485520 [label=AccumulateGrad]
	139936693485232 -> 139936693484272
	139936693485232 [label=TBackward]
	139936693485376 -> 139936693485232
	139936675258816 [label="model.lane2actor_attention.attention_layers.3.edge_dist_encoder.0.weight
 (128, 2)" fillcolor=lightblue]
	139936675258816 -> 139936693485376
	139936693485376 [label=AccumulateGrad]
	139936693483216 -> 139936693188112
	139936693483216 -> 139939054092224 [dir=none]
	139939054092224 [label="indices[0]
 (156865)" fillcolor=orange]
	139936693483216 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:       (68, 128)"]
	139936677108944 -> 139936693483216
	139936693188016 -> 139936677107072
	139936693188016 [label=TBackward]
	139936693485280 -> 139936693188016
	139936675259392 [label="model.lane2actor_attention.attention_layers.3.edge_encoder.0.weight
 (128, 384)" fillcolor=lightblue]
	139936675259392 -> 139936693485280
	139936693485280 [label=AccumulateGrad]
	139936677109088 -> 139936677108560
	139936677109088 [label=TBackward]
	139936693189840 -> 139936677109088
	139936675259648 [label="model.lane2actor_attention.attention_layers.3.edge_encoder.2.weight
 (128, 128)" fillcolor=lightblue]
	139936675259648 -> 139936693189840
	139936693189840 [label=AccumulateGrad]
	139936677107792 -> 139936677107600
	139936675260416 [label="model.lane2actor_attention.attention_layers.3.dst_feature_norm.weight
 (128)" fillcolor=lightblue]
	139936675260416 -> 139936677107792
	139936677107792 [label=AccumulateGrad]
	139936677107984 -> 139936677107600
	139936675260288 [label="model.lane2actor_attention.attention_layers.3.dst_feature_norm.bias
 (128)" fillcolor=lightblue]
	139936675260288 -> 139936677107984
	139936677107984 [label=AccumulateGrad]
	139936677106976 -> 139936677106400
	139936677106976 [label=TBackward]
	139936677108656 -> 139936677106976
	139936675260032 [label="model.lane2actor_attention.attention_layers.3.output_linear.weight
 (128, 128)" fillcolor=lightblue]
	139936675260032 -> 139936677108656
	139936677108656 [label=AccumulateGrad]
	139936677106640 -> 139936677105872
	139936677107648 -> 139936677457152
	139936677107648 [label=TBackward]
	139936677107120 -> 139936677107648
	139936675262016 [label="model.actor2actor_attention.attention_layers.0.dst_encoder.0.weight
 (128, 128)" fillcolor=lightblue]
	139936675262016 -> 139936677107120
	139936677107120 [label=AccumulateGrad]
	139936677456048 -> 139936677454464
	139936677456048 -> 139939054091840 [dir=none]
	139939054091840 [label="mat1
 (590, 128)" fillcolor=orange]
	139936677456048 -> 139939054091264 [dir=none]
	139939054091264 [label="mat2
 (128, 128)" fillcolor=orange]
	139936677456048 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (590, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139936677457488 -> 139936677456048
	139936657560704 [label="model.actor2actor_attention.attention_layers.0.edge_encoder.2.bias
 (128)" fillcolor=lightblue]
	139936657560704 -> 139936677457488
	139936677457488 [label=AccumulateGrad]
	139936677456528 -> 139936677456048
	139936677456528 -> 139938013516352 [dir=none]
	139938013516352 [label="result
 (590, 128)" fillcolor=orange]
	139936677456528 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936677107888 -> 139936677456528
	139936677107888 -> 139939054092160 [dir=none]
	139939054092160 [label="mat1
 (590, 384)" fillcolor=orange]
	139936677107888 -> 139938013518912 [dir=none]
	139938013518912 [label="mat2
 (384, 128)" fillcolor=orange]
	139936677107888 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (590, 384)
mat1_strides:       (384, 1)
mat2        : [saved tensor]
mat2_sizes  :     (384, 128)
mat2_strides:       (1, 384)"]
	139936677107504 -> 139936677107888
	139936657560384 [label="model.actor2actor_attention.attention_layers.0.edge_encoder.0.bias
 (128)" fillcolor=lightblue]
	139936657560384 -> 139936677107504
	139936677107504 [label=AccumulateGrad]
	139936677106304 -> 139936677107888
	139936677106304 [label="CatBackward
-------------------------
dim: 18446744073709551615"]
	139936693481968 -> 139936677106304
	139936693481968 -> 139938013516096 [dir=none]
	139938013516096 [label="indices[0]
 (590)" fillcolor=orange]
	139936693481968 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:       (68, 128)"]
	139936693482112 -> 139936693481968
	139936693482112 -> 139939054090432 [dir=none]
	139939054090432 [label="result
 (68, 128)" fillcolor=orange]
	139936693482112 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936693482400 -> 139936693482112
	139936693482400 -> 139936677537024 [dir=none]
	139936677537024 [label="mat1
 (68, 128)" fillcolor=orange]
	139936693482400 -> 139936677538048 [dir=none]
	139936677538048 [label="mat2
 (128, 128)" fillcolor=orange]
	139936693482400 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (68, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139936693482640 -> 139936693482400
	139936675261440 [label="model.actor2actor_attention.attention_layers.0.src_encoder.0.bias
 (128)" fillcolor=lightblue]
	139936675261440 -> 139936693482640
	139936693482640 [label=AccumulateGrad]
	139936677456192 -> 139936693482400
	139936693482448 -> 139936693482400
	139936693482448 [label=TBackward]
	139936693482928 -> 139936693482448
	139936675261376 [label="model.actor2actor_attention.attention_layers.0.src_encoder.0.weight
 (128, 128)" fillcolor=lightblue]
	139936675261376 -> 139936693482928
	139936693482928 [label=AccumulateGrad]
	139936693484800 -> 139936677106304
	139936693484800 -> 139936677537152 [dir=none]
	139936677537152 [label="result
 (590, 128)" fillcolor=orange]
	139936693484800 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936693481680 -> 139936693484800
	139936693481680 -> 139936677536064 [dir=none]
	139936677536064 [label="mat1
 (590, 2)" fillcolor=orange]
	139936693481680 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :       (590, 2)
mat1_strides:             ()
mat2        :           None
mat2_sizes  :       (2, 128)
mat2_strides:         (1, 2)"]
	139936693483888 -> 139936693481680
	139936657559808 [label="model.actor2actor_attention.attention_layers.0.edge_dist_encoder.0.bias
 (128)" fillcolor=lightblue]
	139936657559808 -> 139936693483888
	139936693483888 [label=AccumulateGrad]
	139936693482976 -> 139936693481680
	139936693482976 [label=TBackward]
	139936693483408 -> 139936693482976
	139936657559680 [label="model.actor2actor_attention.attention_layers.0.edge_dist_encoder.0.weight
 (128, 2)" fillcolor=lightblue]
	139936657559680 -> 139936693483408
	139936693483408 [label=AccumulateGrad]
	139936693481728 -> 139936677106304
	139936693481728 -> 139936677538368 [dir=none]
	139936677538368 [label="indices[0]
 (590)" fillcolor=orange]
	139936693481728 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:       (68, 128)"]
	139936677454848 -> 139936693481728
	139936693483984 -> 139936677107888
	139936693483984 [label=TBackward]
	139936693483120 -> 139936693483984
	139936657560256 [label="model.actor2actor_attention.attention_layers.0.edge_encoder.0.weight
 (128, 384)" fillcolor=lightblue]
	139936657560256 -> 139936693483120
	139936693483120 [label=AccumulateGrad]
	139936677108992 -> 139936677456048
	139936677108992 [label=TBackward]
	139936677108176 -> 139936677108992
	139936657560512 [label="model.actor2actor_attention.attention_layers.0.edge_encoder.2.weight
 (128, 128)" fillcolor=lightblue]
	139936657560512 -> 139936677108176
	139936677108176 [label=AccumulateGrad]
	139936677454272 -> 139936677457392
	139936657561280 [label="model.actor2actor_attention.attention_layers.0.dst_feature_norm.weight
 (128)" fillcolor=lightblue]
	139936657561280 -> 139936677454272
	139936677454272 [label=AccumulateGrad]
	139936677457728 -> 139936677457392
	139936657561152 [label="model.actor2actor_attention.attention_layers.0.dst_feature_norm.bias
 (128)" fillcolor=lightblue]
	139936657561152 -> 139936677457728
	139936677457728 [label=AccumulateGrad]
	139936677456720 -> 139936677456864
	139936677456720 [label=TBackward]
	139936677454560 -> 139936677456720
	139936657560896 [label="model.actor2actor_attention.attention_layers.0.output_linear.weight
 (128, 128)" fillcolor=lightblue]
	139936657560896 -> 139936677454560
	139936677454560 [label=AccumulateGrad]
	139936677456192 -> 139936677454944
	139936677455760 -> 139936677456096
	139936677455760 [label=TBackward]
	139936677106208 -> 139936677455760
	139936657562368 [label="model.actor2actor_attention.attention_layers.1.dst_encoder.0.weight
 (128, 128)" fillcolor=lightblue]
	139936657562368 -> 139936677106208
	139936677106208 [label=AccumulateGrad]
	139938013212336 -> 139938013211472
	139938013212336 -> 139936677538304 [dir=none]
	139936677538304 [label="mat1
 (590, 128)" fillcolor=orange]
	139938013212336 -> 139936677537472 [dir=none]
	139936677537472 [label="mat2
 (128, 128)" fillcolor=orange]
	139938013212336 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (590, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139938013210560 -> 139938013212336
	139936657400128 [label="model.actor2actor_attention.attention_layers.1.edge_encoder.2.bias
 (128)" fillcolor=lightblue]
	139936657400128 -> 139938013210560
	139938013210560 [label=AccumulateGrad]
	139936677456768 -> 139938013212336
	139936677456768 -> 139936677537664 [dir=none]
	139936677537664 [label="result
 (590, 128)" fillcolor=orange]
	139936677456768 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936677454752 -> 139936677456768
	139936677454752 -> 139936677536576 [dir=none]
	139936677536576 [label="mat1
 (590, 384)" fillcolor=orange]
	139936677454752 -> 139936677538752 [dir=none]
	139936677538752 [label="mat2
 (384, 128)" fillcolor=orange]
	139936677454752 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (590, 384)
mat1_strides:       (384, 1)
mat2        : [saved tensor]
mat2_sizes  :     (384, 128)
mat2_strides:       (1, 384)"]
	139936677457872 -> 139936677454752
	139936657399872 [label="model.actor2actor_attention.attention_layers.1.edge_encoder.0.bias
 (128)" fillcolor=lightblue]
	139936657399872 -> 139936677457872
	139936677457872 [label=AccumulateGrad]
	139936677455952 -> 139936677454752
	139936677455952 [label="CatBackward
-------------------------
dim: 18446744073709551615"]
	139936693484368 -> 139936677455952
	139936693484368 -> 139936677538560 [dir=none]
	139936677538560 [label="indices[0]
 (590)" fillcolor=orange]
	139936693484368 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:       (68, 128)"]
	139936693482688 -> 139936693484368
	139936693482688 -> 139936677536192 [dir=none]
	139936677536192 [label="result
 (68, 128)" fillcolor=orange]
	139936693482688 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936693481920 -> 139936693482688
	139936693481920 -> 139936677537792 [dir=none]
	139936677537792 [label="mat1
 (68, 128)" fillcolor=orange]
	139936693481920 -> 139936677537344 [dir=none]
	139936677537344 [label="mat2
 (128, 128)" fillcolor=orange]
	139936693481920 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (68, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139936693484128 -> 139936693481920
	139936657561664 [label="model.actor2actor_attention.attention_layers.1.src_encoder.0.bias
 (128)" fillcolor=lightblue]
	139936657561664 -> 139936693484128
	139936693484128 [label=AccumulateGrad]
	139938013209312 -> 139936693481920
	139936692279232 -> 139936693481920
	139936692279232 [label=TBackward]
	139936692279808 -> 139936692279232
	139936657561728 [label="model.actor2actor_attention.attention_layers.1.src_encoder.0.weight
 (128, 128)" fillcolor=lightblue]
	139936657561728 -> 139936692279808
	139936692279808 [label=AccumulateGrad]
	139936693482208 -> 139936677455952
	139936693482208 -> 139936677537216 [dir=none]
	139936677537216 [label="result
 (590, 128)" fillcolor=orange]
	139936693482208 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936693481776 -> 139936693482208
	139936693481776 -> 139936677536448 [dir=none]
	139936677536448 [label="mat1
 (590, 2)" fillcolor=orange]
	139936693481776 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :       (590, 2)
mat1_strides:             ()
mat2        :           None
mat2_sizes  :       (2, 128)
mat2_strides:         (1, 2)"]
	139936692278032 -> 139936693481776
	139936657563008 [label="model.actor2actor_attention.attention_layers.1.edge_dist_encoder.0.bias
 (128)" fillcolor=lightblue]
	139936657563008 -> 139936692278032
	139936692278032 [label=AccumulateGrad]
	139936692280912 -> 139936693481776
	139936692280912 [label=TBackward]
	139936692277552 -> 139936692280912
	139936657562880 [label="model.actor2actor_attention.attention_layers.1.edge_dist_encoder.0.weight
 (128, 2)" fillcolor=lightblue]
	139936657562880 -> 139936692277552
	139936692277552 [label=AccumulateGrad]
	139936693482064 -> 139936677455952
	139936693482064 -> 139936677538112 [dir=none]
	139936677538112 [label="indices[0]
 (590)" fillcolor=orange]
	139936693482064 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:       (68, 128)"]
	139938013212432 -> 139936693482064
	139936693481536 -> 139936677454752
	139936693481536 [label=TBackward]
	139936693484896 -> 139936693481536
	139936657563456 [label="model.actor2actor_attention.attention_layers.1.edge_encoder.0.weight
 (128, 384)" fillcolor=lightblue]
	139936657563456 -> 139936693484896
	139936693484896 [label=AccumulateGrad]
	139936677456240 -> 139938013212336
	139936677456240 [label=TBackward]
	139936677457536 -> 139936677456240
	139936657399936 [label="model.actor2actor_attention.attention_layers.1.edge_encoder.2.weight
 (128, 128)" fillcolor=lightblue]
	139936657399936 -> 139936677457536
	139936677457536 [label=AccumulateGrad]
	139938013211664 -> 139938013210512
	139936657400704 [label="model.actor2actor_attention.attention_layers.1.dst_feature_norm.weight
 (128)" fillcolor=lightblue]
	139936657400704 -> 139938013211664
	139938013211664 [label=AccumulateGrad]
	139938013210992 -> 139938013210512
	139936657400576 [label="model.actor2actor_attention.attention_layers.1.dst_feature_norm.bias
 (128)" fillcolor=lightblue]
	139936657400576 -> 139938013210992
	139938013210992 [label=AccumulateGrad]
	139938013209744 -> 139938013209936
	139938013209744 [label=TBackward]
	139938013211904 -> 139938013209744
	139936657400320 [label="model.actor2actor_attention.attention_layers.1.output_linear.weight
 (128, 128)" fillcolor=lightblue]
	139936657400320 -> 139938013211904
	139938013211904 [label=AccumulateGrad]
	139938013209312 -> 139938013209120
	139936676751968 -> 139936669974736
	139936676751968 [label=TBackward]
	139936677456624 -> 139936676751968
	139936657401792 [label="model.actor2actor_attention.attention_layers.2.dst_encoder.0.weight
 (128, 128)" fillcolor=lightblue]
	139936657401792 -> 139936677456624
	139936677456624 [label=AccumulateGrad]
	139936669978384 -> 139936669978096
	139936669978384 -> 139936677538816 [dir=none]
	139936677538816 [label="mat1
 (590, 128)" fillcolor=orange]
	139936669978384 -> 139936677538688 [dir=none]
	139936677538688 [label="mat2
 (128, 128)" fillcolor=orange]
	139936669978384 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (590, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139936669975552 -> 139936669978384
	139936657403328 [label="model.actor2actor_attention.attention_layers.2.edge_encoder.2.bias
 (128)" fillcolor=lightblue]
	139936657403328 -> 139936669975552
	139936669975552 [label=AccumulateGrad]
	139936669975792 -> 139936669978384
	139936669975792 -> 139936677536640 [dir=none]
	139936677536640 [label="result
 (590, 128)" fillcolor=orange]
	139936669975792 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139938013212096 -> 139936669975792
	139938013212096 -> 139936677536128 [dir=none]
	139936677536128 [label="mat1
 (590, 384)" fillcolor=orange]
	139938013212096 -> 139936677537536 [dir=none]
	139936677537536 [label="mat2
 (384, 128)" fillcolor=orange]
	139938013212096 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (590, 384)
mat1_strides:       (384, 1)
mat2        : [saved tensor]
mat2_sizes  :     (384, 128)
mat2_strides:       (1, 384)"]
	139938013211232 -> 139938013212096
	139936657403008 [label="model.actor2actor_attention.attention_layers.2.edge_encoder.0.bias
 (128)" fillcolor=lightblue]
	139936657403008 -> 139938013211232
	139938013211232 [label=AccumulateGrad]
	139938013208832 -> 139938013212096
	139938013208832 [label="CatBackward
-------------------------
dim: 18446744073709551615"]
	139936693482016 -> 139938013208832
	139936693482016 -> 139936677538240 [dir=none]
	139936677538240 [label="indices[0]
 (590)" fillcolor=orange]
	139936693482016 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:       (68, 128)"]
	139936692277360 -> 139936693482016
	139936692277360 -> 139936677538624 [dir=none]
	139936677538624 [label="result
 (68, 128)" fillcolor=orange]
	139936692277360 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936692277456 -> 139936692277360
	139936692277456 -> 139936677537984 [dir=none]
	139936677537984 [label="mat1
 (68, 128)" fillcolor=orange]
	139936692277456 -> 139936677537920 [dir=none]
	139936677537920 [label="mat2
 (128, 128)" fillcolor=orange]
	139936692277456 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (68, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139936692277648 -> 139936692277456
	139936657401088 [label="model.actor2actor_attention.attention_layers.2.src_encoder.0.bias
 (128)" fillcolor=lightblue]
	139936657401088 -> 139936692277648
	139936692277648 [label=AccumulateGrad]
	139936669975600 -> 139936692277456
	139936692277600 -> 139936692277456
	139936692277600 [label=TBackward]
	139936692277696 -> 139936692277600
	139936657401152 [label="model.actor2actor_attention.attention_layers.2.src_encoder.0.weight
 (128, 128)" fillcolor=lightblue]
	139936657401152 -> 139936692277696
	139936692277696 [label=AccumulateGrad]
	139936692279952 -> 139938013208832
	139936692279952 -> 139936677536704 [dir=none]
	139936677536704 [label="result
 (590, 128)" fillcolor=orange]
	139936692279952 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936692279472 -> 139936692279952
	139936692279472 -> 139936677536512 [dir=none]
	139936677536512 [label="mat1
 (590, 2)" fillcolor=orange]
	139936692279472 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :       (590, 2)
mat1_strides:             ()
mat2        :           None
mat2_sizes  :       (2, 128)
mat2_strides:         (1, 2)"]
	139936692277888 -> 139936692279472
	139936657402432 [label="model.actor2actor_attention.attention_layers.2.edge_dist_encoder.0.bias
 (128)" fillcolor=lightblue]
	139936657402432 -> 139936692277888
	139936692277888 [label=AccumulateGrad]
	139936692277744 -> 139936692279472
	139936692277744 [label=TBackward]
	139936692277840 -> 139936692277744
	139936657402304 [label="model.actor2actor_attention.attention_layers.2.edge_dist_encoder.0.weight
 (128, 2)" fillcolor=lightblue]
	139936657402304 -> 139936692277840
	139936692277840 [label=AccumulateGrad]
	139936692277504 -> 139938013208832
	139936692277504 -> 139936677536832 [dir=none]
	139936677536832 [label="indices[0]
 (590)" fillcolor=orange]
	139936692277504 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:       (68, 128)"]
	139936669978432 -> 139936692277504
	139936693483936 -> 139938013212096
	139936693483936 [label=TBackward]
	139936692277792 -> 139936693483936
	139936657402880 [label="model.actor2actor_attention.attention_layers.2.edge_encoder.0.weight
 (128, 384)" fillcolor=lightblue]
	139936657402880 -> 139936692277792
	139936692277792 [label=AccumulateGrad]
	139938013212240 -> 139936669978384
	139938013212240 [label=TBackward]
	139936693484512 -> 139938013212240
	139936657403136 [label="model.actor2actor_attention.attention_layers.2.edge_encoder.2.weight
 (128, 128)" fillcolor=lightblue]
	139936657403136 -> 139936693484512
	139936693484512 [label=AccumulateGrad]
	139936669977280 -> 139936669977040
	139936657403776 [label="model.actor2actor_attention.attention_layers.2.dst_feature_norm.weight
 (128)" fillcolor=lightblue]
	139936657403776 -> 139936669977280
	139936669977280 [label=AccumulateGrad]
	139936669977472 -> 139936669977040
	139936658264128 [label="model.actor2actor_attention.attention_layers.2.dst_feature_norm.bias
 (128)" fillcolor=lightblue]
	139936658264128 -> 139936669977472
	139936669977472 [label=AccumulateGrad]
	139936669976032 -> 139936669975264
	139936669976032 [label=TBackward]
	139936669976752 -> 139936669976032
	139936658264320 [label="model.actor2actor_attention.attention_layers.2.output_linear.weight
 (128, 128)" fillcolor=lightblue]
	139936658264320 -> 139936669976752
	139936669976752 [label=AccumulateGrad]
	139936669975600 -> 139936676858368
	139936676858176 -> 139936676748208
	139936676858176 [label=TBackward]
	139938013209552 -> 139936676858176
	139936658265216 [label="model.actor2actor_attention.attention_layers.3.dst_encoder.0.weight
 (128, 128)" fillcolor=lightblue]
	139936658265216 -> 139938013209552
	139938013209552 [label=AccumulateGrad]
	139936676745856 -> 139936676746624
	139936676745856 -> 139936677536384 [dir=none]
	139936677536384 [label="mat1
 (590, 128)" fillcolor=orange]
	139936676745856 -> 139936677538432 [dir=none]
	139936677538432 [label="mat2
 (128, 128)" fillcolor=orange]
	139936676745856 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (590, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139938013210752 -> 139936676745856
	139936658266752 [label="model.actor2actor_attention.attention_layers.3.edge_encoder.2.bias
 (128)" fillcolor=lightblue]
	139936658266752 -> 139938013210752
	139938013210752 [label=AccumulateGrad]
	139936676749264 -> 139936676745856
	139936676749264 -> 139936677536000 [dir=none]
	139936677536000 [label="result
 (590, 128)" fillcolor=orange]
	139936676749264 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936676857744 -> 139936676749264
	139936676857744 -> 139936691049472 [dir=none]
	139936691049472 [label="mat1
 (590, 384)" fillcolor=orange]
	139936676857744 -> 139936691050048 [dir=none]
	139936691050048 [label="mat2
 (384, 128)" fillcolor=orange]
	139936676857744 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :     (590, 384)
mat1_strides:       (384, 1)
mat2        : [saved tensor]
mat2_sizes  :     (384, 128)
mat2_strides:       (1, 384)"]
	139936669976800 -> 139936676857744
	139936658266432 [label="model.actor2actor_attention.attention_layers.3.edge_encoder.0.bias
 (128)" fillcolor=lightblue]
	139936658266432 -> 139936669976800
	139936669976800 [label=AccumulateGrad]
	139936669977760 -> 139936676857744
	139936669977760 [label="CatBackward
-------------------------
dim: 18446744073709551615"]
	139936692278080 -> 139936669977760
	139936692278080 -> 139936691049728 [dir=none]
	139936691049728 [label="indices[0]
 (590)" fillcolor=orange]
	139936692278080 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:       (68, 128)"]
	139936692278176 -> 139936692278080
	139936692278176 -> 139936691050304 [dir=none]
	139936691050304 [label="result
 (68, 128)" fillcolor=orange]
	139936692278176 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936692278272 -> 139936692278176
	139936692278272 -> 139936691050240 [dir=none]
	139936691050240 [label="mat1
 (68, 128)" fillcolor=orange]
	139936692278272 -> 139936691050496 [dir=none]
	139936691050496 [label="mat2
 (128, 128)" fillcolor=orange]
	139936692278272 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :      (68, 128)
mat1_strides:       (128, 1)
mat2        : [saved tensor]
mat2_sizes  :     (128, 128)
mat2_strides:       (1, 128)"]
	139936692278368 -> 139936692278272
	139936658264512 [label="model.actor2actor_attention.attention_layers.3.src_encoder.0.bias
 (128)" fillcolor=lightblue]
	139936658264512 -> 139936692278368
	139936692278368 [label=AccumulateGrad]
	139936687234064 -> 139936692278272
	139936692278320 -> 139936692278272
	139936692278320 [label=TBackward]
	139936692278416 -> 139936692278320
	139936658264576 [label="model.actor2actor_attention.attention_layers.3.src_encoder.0.weight
 (128, 128)" fillcolor=lightblue]
	139936658264576 -> 139936692278416
	139936692278416 [label=AccumulateGrad]
	139936692277408 -> 139936669977760
	139936692277408 -> 139936691049536 [dir=none]
	139936691049536 [label="result
 (590, 128)" fillcolor=orange]
	139936692277408 [label="ReluBackward1
----------------------
result: [saved tensor]"]
	139936692277984 -> 139936692277408
	139936692277984 -> 139936691049024 [dir=none]
	139936691049024 [label="mat1
 (590, 2)" fillcolor=orange]
	139936692277984 [label="AddmmBackward
----------------------------
alpha       :              1
beta        :              1
mat1        : [saved tensor]
mat1_sizes  :       (590, 2)
mat1_strides:             ()
mat2        :           None
mat2_sizes  :       (2, 128)
mat2_strides:         (1, 2)"]
	139936692278656 -> 139936692277984
	139936658265856 [label="model.actor2actor_attention.attention_layers.3.edge_dist_encoder.0.bias
 (128)" fillcolor=lightblue]
	139936658265856 -> 139936692278656
	139936692278656 [label=AccumulateGrad]
	139936692278464 -> 139936692277984
	139936692278464 [label=TBackward]
	139936692278608 -> 139936692278464
	139936658265728 [label="model.actor2actor_attention.attention_layers.3.edge_dist_encoder.0.weight
 (128, 2)" fillcolor=lightblue]
	139936658265728 -> 139936692278608
	139936692278608 [label=AccumulateGrad]
	139936692278992 -> 139936669977760
	139936692278992 -> 139936691051072 [dir=none]
	139936691051072 [label="indices[0]
 (590)" fillcolor=orange]
	139936692278992 [label="IndexBackward
---------------------------
indices   : [saved tensors]
self_sizes:       (68, 128)"]
	139936676748496 -> 139936692278992
	139936669975024 -> 139936676857744
	139936669975024 [label=TBackward]
	139936692278560 -> 139936669975024
	139936658266304 [label="model.actor2actor_attention.attention_layers.3.edge_encoder.0.weight
 (128, 384)" fillcolor=lightblue]
	139936658266304 -> 139936692278560
	139936692278560 [label=AccumulateGrad]
	139936676746528 -> 139936676745856
	139936676746528 [label=TBackward]
	139936669976368 -> 139936676746528
	139936658266560 [label="model.actor2actor_attention.attention_layers.3.edge_encoder.2.weight
 (128, 128)" fillcolor=lightblue]
	139936658266560 -> 139936669976368
	139936669976368 [label=AccumulateGrad]
	139936676748448 -> 139936687234688
	139936658267328 [label="model.actor2actor_attention.attention_layers.3.dst_feature_norm.weight
 (128)" fillcolor=lightblue]
	139936658267328 -> 139936676748448
	139936676748448 [label=AccumulateGrad]
	139936676747680 -> 139936687234688
	139936658267200 [label="model.actor2actor_attention.attention_layers.3.dst_feature_norm.bias
 (128)" fillcolor=lightblue]
	139936658267200 -> 139936676747680
	139936676747680 [label=AccumulateGrad]
	139936687234592 -> 139936687233824
	139936687234592 [label=TBackward]
	139936676746384 -> 139936687234592
	139936658266944 [label="model.actor2actor_attention.attention_layers.3.output_linear.weight
 (128, 128)" fillcolor=lightblue]
	139936658266944 -> 139936676746384
	139936676746384 [label=AccumulateGrad]
	139936687234064 -> 139936687233392
	139938008420016 -> 139938008419056
	139938008420016 [label=TBackward]
	139936676858080 -> 139938008420016
	139936658267520 [label="model._mlp.0.weight
 (128, 128)" fillcolor=lightblue]
	139936658267520 -> 139936676858080
	139936676858080 [label=AccumulateGrad]
	139938008417184 -> 139938008416368
	139938008417184 [label=TBackward]
	139936676748304 -> 139938008417184
	139936661291136 [label="model._mlp.2.weight
 (128, 128)" fillcolor=lightblue]
	139936661291136 -> 139936676748304
	139936676748304 [label=AccumulateGrad]
	139936677057872 -> 139936677057296
	139936677057872 [label=TBackward]
	139938008417328 -> 139936677057872
	139936661291456 [label="model._mlp.4.weight
 (48, 128)" fillcolor=lightblue]
	139936661291456 -> 139938008417328
	139938008417328 [label=AccumulateGrad]
	139936677060224 -> 139936689392000
	139936691051008 [label="
 (1, 48)" fillcolor=darkolivegreen3]
	139936677057296 -> 139936691051008
	139936691051008 -> 139936689392000 [style=dotted]
}
